---
name: python_sandbox
description: åœ¨æ²™ç›’ç¯å¢ƒä¸­æ‰§è¡ŒPythonä»£ç ï¼Œç”¨äºæ•°æ®åˆ†æã€å¯è§†åŒ–å’Œç”ŸæˆExcelã€Wordã€PDFç­‰æ–‡ä»¶ã€‚æ”¯æŒæ•°æ®æ¸…æ´—ã€ç»Ÿè®¡åˆ†æã€æœºå™¨å­¦ä¹ ã€å›¾è¡¨ç”Ÿæˆã€æ–‡æ¡£è‡ªåŠ¨åŒ–ç­‰å¤æ‚å·¥ä½œæµã€‚
tool_name: python_sandbox
category: code
priority: 10
tags: ["python", "code", "visualization", "data-analysis", "chart", "document", "automation", "machine-learning", "reporting", "excel", "word", "pdf", "ppt"]
version: 2.5
references: ["matplotlib_cookbook.md", "pandas_cheatsheet.md", "report_generator_workflow.md", "ml_workflow.md", "sympy_cookbook.md","scipy_cookbook.md", "text_analysis_cookbook.md"]
---

# Pythonæ²™ç›’å·¥å…·ä½¿ç”¨æŒ‡å— v2.5 (æœ€ç»ˆå®Œæ•´ä¼˜åŒ–ç‰ˆ)

## ğŸ¯ **æ ¸å¿ƒèƒ½åŠ›æ¦‚è§ˆ**

Pythonæ²™ç›’æ˜¯ä¸€ä¸ª**å¤šåŠŸèƒ½çš„ä»£ç æ‰§è¡Œç¯å¢ƒ**ï¼Œæ”¯æŒï¼š

| åŠŸèƒ½é¢†åŸŸ | ä¸»è¦ç”¨é€” | å…³é”®åº“ |
|---------|---------|-------|
| **æ•°æ®åˆ†æ** | æ•°æ®æ¸…æ´—ã€è½¬æ¢ã€èšåˆ | Pandas, Polars |
| **é«˜æ€§èƒ½è®¡ç®—** | å†…å­˜SQLã€è¡¨è¾¾å¼åŠ é€Ÿ | DuckDB, Numexpr, Bottleneck |
| **å¯è§†åŒ–** | å›¾è¡¨ç”Ÿæˆä¸è‡ªåŠ¨æ•è· | Matplotlib, Seaborn |
| **æ–‡æ¡£è‡ªåŠ¨åŒ–** | Excel/Word/PDF/PPTç”Ÿæˆ | python-docx, reportlab, openpyxl |
| **æœºå™¨å­¦ä¹ ** | æ¨¡å‹è®­ç»ƒä¸è¯„ä¼° | scikit-learn, LightGBM |
| **ç¬¦å·æ•°å­¦** | å…¬å¼è¯æ˜ã€æ–¹ç¨‹æ±‚è§£ | SymPy |
| **ç§‘å­¦è®¡ç®—** | ä¼˜åŒ–ã€ç§¯åˆ†ã€ä¿¡å·å¤„ç† | SciPy |
| **æµç¨‹å›¾ç”Ÿæˆ** | æ¶æ„å›¾ã€æµç¨‹å›¾ | Graphviz, NetworkX |
| **æ–‡æœ¬åˆ†æ** | HTMLè§£æã€æ•°æ®æå– | BeautifulSoup4, lxml |
| **æ€§èƒ½ä¼˜åŒ–** | æœºæ¢°ç¡¬ç›˜ä¼˜åŒ–ã€å¼‚æ­¥IO | aiofiles, joblib |

---

## ğŸ“ **æ–‡ä»¶å¤„ç†æŒ‡å— - ä¸¤ç§æ¨¡å¼å¿…é¡»åˆ†æ¸…**

### **æ¨¡å¼A: å·¥ä½œåŒºæ–‡ä»¶ (`/data` ç›®å½•)**
**ç”¨é€”**: æ•°æ®åˆ†æã€å¤„ç†ã€æŒä¹…åŒ–å­˜å‚¨
**æ”¯æŒæ ¼å¼**: `.csv`, `.xlsx`, `.xls`, `.parquet`, `.json`, `.txt`, `.feather`
**è®¿é—®æ–¹å¼**: ç»å¯¹è·¯å¾„ `/data/æ–‡ä»¶å`
```python
import pandas as pd
df = pd.read_csv('/data/sales.csv')  # âœ… æ­£ç¡®
```

### **æ¨¡å¼B: ä¸Šä¸‹æ–‡æ–‡ä»¶ (Base64åµŒå…¥)**
**ç”¨é€”**: å›¾ç‰‡è¯†åˆ«ã€PDFå†…å®¹æå–
**æ”¯æŒæ ¼å¼**: `.png`, `.jpg`, `.jpeg`, `.pdf`, `.txt`(å°æ–‡ä»¶)
**ç‰¹ç‚¹**: æ–‡ä»¶å†…å®¹ç›´æ¥åµŒå…¥å¯¹è¯ï¼Œ**ä¸åœ¨ `/data` ç›®å½•**
```python
# âŒ é”™è¯¯ï¼šæ— æ³•ä»/dataè¯»å–ä¸Šä¼ çš„å›¾ç‰‡
# img = Image.open('/data/uploaded_image.png')  # ä¼šå¤±è´¥
```

---

## ğŸš€ **è¾“å‡ºè§„èŒƒ - è®°ä½ä¸‰ç§æ–¹å¼**

### **1. å›¾è¡¨è¾“å‡º - ç³»ç»Ÿè‡ªåŠ¨æ•è·**
```python
import matplotlib.pyplot as plt
plt.plot([1,2,3], [4,5,6])
plt.title('ç¤ºä¾‹å›¾è¡¨')
plt.show()  # ğŸ¯ å…³é”®ï¼šè‡ªåŠ¨æ•è·ï¼Œæ— éœ€æ‰‹åŠ¨å¤„ç†
```

### **2. å¯ä¸‹è½½æ–‡ä»¶ - å¿…é¡»ä½¿ç”¨JSONæ ¼å¼**
```python
import base64
import json

# ç”Ÿæˆæ–‡ä»¶å†…å®¹å...
file_data = base64.b64encode(content).decode('utf-8')
output = {
    "type": "excel",  # æˆ– "word", "pdf", "ppt", "image", "analysis_report", "ml_report"
    "title": "é”€å”®æŠ¥å‘Š.xlsx",
    "data_base64": file_data  # å¯¹äºå›¾ç‰‡ç”¨ "image_base64"
}
print(json.dumps(output))  # ğŸ¯ å¿…é¡»ç”¨JSONæ ¼å¼æ‰“å°
```

### **3. æ–‡æœ¬/æ•°æ® - ç›´æ¥print**
```python
print("åˆ†æç»“æœ:")
print(f"æ€»è®¡: {total}")
print(df.describe())  # Pandas DataFrameè‡ªåŠ¨ç¾åŒ–æ˜¾ç¤º
```

---

## ğŸ’¾ **ä¼šè¯æŒä¹…åŒ– - è·¨ä»£ç æ‰§è¡Œçš„æ–‡ä»¶å…±äº«**

### **å·¥ä½œæµç¤ºä¾‹ï¼š**
```python
# ç¬¬ä¸€æ­¥ï¼šå¤„ç†æ•°æ®å¹¶ä¿å­˜
import pandas as pd
df = pd.read_excel('/data/åŸå§‹æ•°æ®.xlsx')
processed = df.groupby('éƒ¨é—¨')['é”€å”®é¢'].sum()
processed.to_csv('/data/éƒ¨é—¨æ±‡æ€».csv')  # âœ… ä¿å­˜ä¸­é—´ç»“æœ
print("å·²ä¿å­˜éƒ¨é—¨æ±‡æ€»æ•°æ®")

# ç¬¬äºŒæ­¥ï¼šè¯»å–ä¸­é—´ç»“æœç»§ç»­åˆ†æ
df_summary = pd.read_csv('/data/éƒ¨é—¨æ±‡æ€».csv')
print(f"è¯»å–åˆ° {len(df_summary)} ä¸ªéƒ¨é—¨çš„æ±‡æ€»æ•°æ®")
```

### **é‡è¦æé†’ï¼š**
- âœ… åŒä¸€ä¼šè¯å†…æ–‡ä»¶æŒä¹…åŒ–ï¼ˆ24å°æ—¶è¶…æ—¶ï¼‰
- âœ… æ–°ä¼šè¯å¼€å§‹æ—¶ `/data` ç›®å½•ä¸ºç©º
- âœ… å»ºè®®ä¿å­˜ä¸­é—´ç»“æœé¿å…é‡å¤è®¡ç®—

---

## ğŸ“š **å·¥ä½œæµå‚è€ƒ - æŒ‰éœ€æŸ¥é˜…**

### **å¿«é€ŸæŸ¥æ‰¾è¡¨ï¼š**

| ä»»åŠ¡ç±»å‹ | å‚è€ƒæ–‡ä»¶ | æ ¸å¿ƒåº“ |
|---------|---------|-------|
| **åˆ›å»ºå›¾è¡¨** | `matplotlib_cookbook.md` | matplotlib, seaborn |
| **æ•°æ®å¤„ç†** | `pandas_cheatsheet.md` | pandas, duckdb |
| **ç”ŸæˆæŠ¥å‘Š** | `report_generator_workflow.md` | python-docx, reportlab |
| **æœºå™¨å­¦ä¹ ** | `ml_workflow.md` | scikit-learn, lightgbm |
| **ç¬¦å·æ•°å­¦** | `sympy_cookbook.md` | sympy |
| **ç§‘å­¦è®¡ç®—** | `scipy_cookbook.md` | scipy |
| **æ–‡æœ¬è§£æ** | `text_analysis_cookbook.md` | beautifulsoup4, lxml |

### **ç¤ºä¾‹å·¥ä½œæµï¼š**

#### **A. å…¬å¼è¯æ˜å·¥ä½œæµ**
```python
# 1. å®šä¹‰ç¬¦å·
import sympy as sp
x, y = sp.symbols('x y')

# 2. æ„å»ºè¡¨è¾¾å¼
lhs = (x + y)**2
rhs = x**2 + 2*x*y + y**2

# 3. éªŒè¯æ’ç­‰
difference = sp.simplify(lhs - rhs)
print(f"å·®å€¼: {difference}")
print(f"æ˜¯å¦æ’ç­‰: {difference == 0}")
```

#### **B. ETLæ•°æ®åˆ†æå·¥ä½œæµ**
```python
# Extract
df = pd.read_csv('/data/raw.csv')

# Transform
df_clean = (df
           .dropna()
           .drop_duplicates()
           .assign(profit = lambda d: d['revenue'] - d['cost']))

# Load
df_clean.to_csv('/data/cleaned.csv', index=False)
print(df_clean.describe())
```

---

## âš¡ **æ€§èƒ½ä¼˜åŒ–æŒ‡å— (v2.5æ ¸å¿ƒä¼˜åŠ¿)**

### **1. å¤§æ–‡ä»¶å¤„ç†ç­–ç•¥**

#### **åˆ†å—è¯»å– (50MB+æ–‡ä»¶)**
```python
chunks = []
for chunk in pd.read_csv('/data/large.csv', chunksize=50000):
    processed = process_chunk(chunk)  # è‡ªå®šä¹‰å¤„ç†å‡½æ•°
    chunks.append(processed)
final_df = pd.concat(chunks, ignore_index=True)
```

#### **æ ¼å¼è½¬æ¢åŠ é€Ÿ**
```python
# è½¬æ¢CSVä¸ºFeatheræ ¼å¼ (æé€Ÿ10-100å€)
import pyarrow.feather as feather
df = pd.read_csv('/data/slow.csv')
feather.write_feather(df, '/data/fast.feather')  # ä¿å­˜

# åç»­è¯»å–æå¿«
df_fast = feather.read_feather('/data/fast.feather')
```

### **2. å†…å­˜å¤–è®¡ç®— (é¿å…OOM)**

#### **DuckDBå†…å­˜SQL**
```python
import duckdb

# ç›´æ¥æŸ¥è¯¢CSVï¼Œä¸åŠ è½½åˆ°å†…å­˜
result = duckdb.sql("""
    SELECT department, 
           AVG(salary) as avg_salary,
           COUNT(*) as count
    FROM read_csv_auto('/data/employees.csv')
    WHERE hire_date > '2024-01-01'
    GROUP BY department
    ORDER BY avg_salary DESC
    LIMIT 10
""").df()  # æœ€åè½¬ä¸ºDataFrame
print(result)
```

#### **Numexprè¡¨è¾¾å¼åŠ é€Ÿ**
```python
import numexpr as ne

# ä¼ ç»Ÿæ–¹å¼ï¼ˆæ…¢ï¼‰
df['result'] = df['A'] * 2 + df['B'] ** 2 - df['C'] / 3

# Numexpræ–¹å¼ï¼ˆå¿«3-5å€ï¼‰
df['result'] = ne.evaluate(
    "A * 2 + B ** 2 - C / 3",
    local_dict={k: df[k].values for k in ['A', 'B', 'C']}
)
```

### **3. é«˜çº§ä¼˜åŒ–æŠ€å·§ (å®Œæ•´ç‰ˆè¡¥å……)**

#### **å¼‚æ­¥æ–‡ä»¶æ“ä½œ - aiofiles**
```python
import aiofiles
import asyncio

async def process_large_file():
    # å¼‚æ­¥è¯»å–ï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹ï¼ˆæœºæ¢°ç¡¬ç›˜ç‰¹åˆ«å—ç›Šï¼‰
    async with aiofiles.open('/data/large_file.csv', 'r') as f:
        content = await f.read()
    
    # å¤„ç†æ•°æ®...
    
    # å¼‚æ­¥å†™å…¥
    async with aiofiles.open('/data/processed.csv', 'w') as f:
        await f.write(processed_content)

# åœ¨å¼‚æ­¥ç¯å¢ƒä¸­è°ƒç”¨
await process_large_file()
```

#### **å†…å­˜ç¼“å­˜ä¸å¹¶è¡Œè®¡ç®— - joblib**
```python
from joblib import Memory
import time

# åˆ›å»ºå†…å­˜ç¼“å­˜ï¼ˆå¯é…ç½®åˆ°ç£ç›˜ï¼‰
cachedir = '/data/cache'
memory = Memory(cachedir, verbose=0)

@memory.cache
def expensive_computation(x, y):
    """è®¡ç®—ç»“æœä¼šè¢«ç¼“å­˜åˆ°ç£ç›˜"""
    time.sleep(2)  # æ¨¡æ‹Ÿè€—æ—¶è®¡ç®—
    return x * y + x**2

# ç¬¬ä¸€æ¬¡è®¡ç®—æ…¢ï¼Œåç»­ä»ç£ç›˜è¯»å–å¿«
result1 = expensive_computation(10, 20)  # æ…¢
result2 = expensive_computation(10, 20)  # å¿«ï¼ˆä»ç¼“å­˜ï¼‰
```

#### **DuckDBæ›¿ä»£Pandasé‡æ“ä½œ**
```python
import duckdb

# âŒ è€—å†…å­˜çš„Pandasæ“ä½œ
# df = pd.read_csv('/data/large.csv')
# result = df.groupby('category').agg({'value': ['mean', 'sum', 'count']})

# âœ… å†…å­˜å‹å¥½çš„DuckDBæ“ä½œ
result = duckdb.sql("""
    SELECT category, 
           AVG(value) as mean_value,
           SUM(value) as sum_value,
           COUNT(value) as count_value
    FROM read_csv('/data/large.csv')
    GROUP BY category
""").df()
```

---

## ğŸ“‹ **å¯ç”¨åº“å¿«é€Ÿå‚è€ƒ (v2.5)**

### **æ•°æ®å¤„ç†æ ¸å¿ƒ**
```python
import pandas as pd          # æ•°æ®åˆ†æ (v2.2.2)
import numpy as np           # æ•°å€¼è®¡ç®— (v1.26.4)
import duckdb                # å†…å­˜SQL (v0.10.2) - v2.5æ–°å¢
import numexpr as ne         # è¡¨è¾¾å¼åŠ é€Ÿ (v2.10.0) - v2.5æ–°å¢
import bottleneck as bn      # æ»šåŠ¨ç»Ÿè®¡åŠ é€Ÿ (v1.3.8) - v2.5æ–°å¢
import pyarrow.feather as feather  # Featheræ ¼å¼æ”¯æŒ (v14.0.2)
```

### **æœºå™¨å­¦ä¹ å¢å¼º**
```python
from sklearn.ensemble import RandomForestClassifier  # scikit-learn v1.5.0
import lightgbm as lgb       # æ¢¯åº¦æå‡æ ‘ (v4.3.0) - v2.5æ–°å¢
import category_encoders as ce  # åˆ†ç±»ç¼–ç  (v2.6.3) - v2.5æ–°å¢
from skopt import BayesSearchCV  # è´å¶æ–¯ä¼˜åŒ– (v0.9.0) - v2.5æ–°å¢
import statsmodels.api as sm  # ç»Ÿè®¡æ¨¡å‹ (v0.14.1)
```

### **å¯è§†åŒ–ä¸å›¾è¡¨**
```python
import matplotlib.pyplot as plt  # åŸºç¡€ç»˜å›¾ (v3.8.4)
import seaborn as sns            # ç»Ÿè®¡å¯è§†åŒ– (v0.13.2)
import graphviz                  # æµç¨‹å›¾ (è‡ªåŠ¨å¸ƒå±€)
import networkx as nx            # ç½‘ç»œå›¾
```

### **æ–‡æ¡£ç”Ÿæˆ**
```python
from docx import Document        # Wordæ–‡æ¡£ (v1.1.2)
from reportlab.lib.pagesizes import letter  # PDFç”Ÿæˆ (v4.0.7)
from pptx import Presentation    # PPTæ¼”ç¤ºæ–‡ç¨¿ (v0.6.23)
import openpyxl                  # Excelæ“ä½œ (v3.1.2)
```

### **ç§‘å­¦è®¡ç®—ä¸æ•°å­¦**
```python
import sympy as sp               # ç¬¦å·æ•°å­¦ (v1.12)
import scipy                     # ç§‘å­¦è®¡ç®— (v1.14.1)
import scipy.optimize as opt     # ä¼˜åŒ–ç®—æ³•
```

### **ç½‘é¡µå†…å®¹å¤„ç†**
```python
from bs4 import BeautifulSoup    # HTMLè§£æ (v4.12.3)
import lxml                      # é«˜æ€§èƒ½è§£æå™¨ (v5.2.2)
from tabulate import tabulate    # æ ¼å¼åŒ–è¡¨æ ¼ (v0.9.0)
```

### **æ€§èƒ½ä¼˜åŒ–ä¸å·¥å…·**
```python
from tqdm import tqdm            # è¿›åº¦æ¡æ˜¾ç¤º (v4.66.4) - v2.5æ–°å¢
from joblib import Memory        # ç£ç›˜ç¼“å­˜å’Œå¹¶è¡Œ (v1.3.2) - v2.5æ–°å¢
import aiofiles                  # å¼‚æ­¥æ–‡ä»¶æ“ä½œ (v24.1.0) - v2.5æ–°å¢
```

---

## ğŸš¨ **é‡è¦é™åˆ¶ä¸æœ€ä½³å®è·µ**

### **âœ… å¿…é¡»éµå®ˆçš„è§„åˆ™**
1. **å›¾è¡¨è¾“å‡º**: æ€»æ˜¯ä½¿ç”¨ `plt.show()`ï¼Œç³»ç»Ÿè‡ªåŠ¨æ•è·
2. **æ–‡ä»¶ç”Ÿæˆ**: å¿…é¡»è¾“å‡ºç‰¹å®šJSONæ ¼å¼ç»™å¯ä¸‹è½½æ–‡ä»¶
3. **æ–‡ä»¶è®¿é—®**: æ•°æ®æ–‡ä»¶åœ¨ `/data` ç›®å½•ï¼Œåª’ä½“æ–‡ä»¶åœ¨ä¸Šä¸‹æ–‡ä¸­
4. **å†…å­˜ç®¡ç†**: å®¹å™¨é™åˆ¶6GBï¼Œé¿å…ä½¿ç”¨swap

### **âŒ ç¦æ­¢çš„æ“ä½œ**
```python
# ä»¥ä¸‹æ“ä½œä¼šè¢«é˜»æ­¢ï¼š
exec("å±é™©ä»£ç ")                 # âŒ åŠ¨æ€æ‰§è¡Œ
__import__('os').system('rm')   # âŒ ç³»ç»Ÿå‘½ä»¤
open('/etc/passwd')             # âŒ è®¿é—®ç³»ç»Ÿæ–‡ä»¶
class MyClass:                   # âŒ ç±»å®šä¹‰
    pass
```

### **âš ï¸ æ€§èƒ½è­¦å‘Š**
1. **å¤§æ–‡ä»¶**: >50MBæ—¶ä½¿ç”¨åˆ†å—å¤„ç†
2. **å¤æ‚è®¡ç®—**: ä½¿ç”¨DuckDBæˆ–NumexpråŠ é€Ÿ
3. **é‡å¤æ“ä½œ**: ä½¿ç”¨Featheræ ¼å¼ç¼“å­˜ä¸­é—´ç»“æœ
4. **å†…å­˜ç›‘æ§**: åŠæ—¶åˆ é™¤å¤§å˜é‡ `del large_df`

### **ğŸ”§ é«˜çº§ä½¿ç”¨å»ºè®®**
1. **çº¯å‡½æ•°å¼ç¼–ç¨‹**: ä½¿ç”¨å­—å…¸å’Œåˆ—è¡¨ç»„ç»‡æ•°æ®ï¼Œé¿å…ç±»å®šä¹‰
2. **å¤æ‚é€»è¾‘æ‹†åˆ†**: å°†å¤æ‚ä»»åŠ¡æ‹†åˆ†ä¸ºå¤šä¸ªå°å‡½æ•°
3. **åˆ†æ­¥éª¤æ‰§è¡Œ**: åˆ©ç”¨ä¼šè¯æŒä¹…åŒ–ï¼Œåˆ†æ­¥æ‰§è¡Œå¤æ‚åˆ†æ

---

## ğŸ”§ **æ•…éšœæ’é™¤ä¸è°ƒè¯•**

### **å¸¸è§é—®é¢˜è§£å†³**

#### **é—®é¢˜1: å†…å­˜ä¸è¶³**
```python
# âŒ é”™è¯¯åšæ³•
df = pd.read_csv('/data/huge.csv')  # å¯èƒ½å´©æºƒ

# âœ… æ­£ç¡®åšæ³•
# æ–¹æ¡ˆA: åˆ†å—å¤„ç†
for chunk in pd.read_csv('/data/huge.csv', chunksize=50000):
    process(chunk)

# æ–¹æ¡ˆB: ä½¿ç”¨DuckDBå†…å­˜å¤–æŸ¥è¯¢
result = duckdb.sql("SELECT * FROM read_csv_auto('/data/huge.csv') LIMIT 10000").df()

# æ–¹æ¡ˆC: è½¬æ¢ä¸ºFeatheræ ¼å¼
import pyarrow.feather as feather
df = pd.read_csv('/data/huge.csv')
feather.write_feather(df, '/data/huge.feather')  # ä¿å­˜ä¸ºé«˜æ•ˆæ ¼å¼
df_fast = feather.read_feather('/data/huge.feather')  # å¿«é€Ÿè¯»å–
```

#### **é—®é¢˜2: å¤„ç†é€Ÿåº¦æ…¢**
```python
# âŒ æ…¢é€ŸPandasæ“ä½œ
df['result'] = df['A'] * 2 + df['B'] ** 2 - df['C'] / 3

# âœ… ä½¿ç”¨NumexpråŠ é€Ÿ
df['result'] = ne.evaluate("A * 2 + B ** 2 - C / 3", 
                          {k: df[k].values for k in ['A', 'B', 'C']})

# âœ… ä½¿ç”¨BottleneckåŠ é€Ÿæ»šåŠ¨ç»Ÿè®¡
import bottleneck as bn
df['rolling_mean'] = bn.move_mean(df['value'], window=20)
```

#### **é—®é¢˜3: å›¾è¡¨ä¸æ˜¾ç¤º**
```python
# âŒ ç¼ºå°‘show()
plt.plot(x, y)
plt.title('å›¾è¡¨')

# âœ… å¿…é¡»è°ƒç”¨show()
plt.plot(x, y)
plt.title('å›¾è¡¨')
plt.show()  # ğŸ¯ å…³é”®ï¼
```

#### **é—®é¢˜4: å¤§å‹æ–‡ä»¶IOæ…¢**
```python
# âŒ åŒæ­¥IOé˜»å¡
with open('/data/large.txt', 'r') as f:
    content = f.read()  # é˜»å¡ä¸»çº¿ç¨‹

# âœ… å¼‚æ­¥IO (æœºæ¢°ç¡¬ç›˜ç‰¹åˆ«æœ‰æ•ˆ)
import aiofiles
import asyncio

async def read_file_async():
    async with aiofiles.open('/data/large.txt', 'r') as f:
        return await f.read()
```

### **æ€§èƒ½ç›‘æ§å‘½ä»¤ (å®Œæ•´ç‰ˆè¡¥å……)**
```bash
# ç›‘æ§å†…å­˜ä½¿ç”¨
watch -n 2 "free -h | grep -E 'Mem|Swap'"

# ç›‘æ§ç£ç›˜IOï¼ˆæœºæ¢°ç¡¬ç›˜å…³é”®æŒ‡æ ‡ï¼‰
iostat -x 2

# ç›‘æ§Dockerå®¹å™¨
docker stats --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.MemPerc}}"
```

---

## ğŸ“ˆ **ç‰ˆæœ¬æ›´æ–°æ—¥å¿—**

### **v2.5 æ ¸å¿ƒå‡çº§**
1. **æ€§èƒ½åº“æ–°å¢**: DuckDB (å†…å­˜SQL)ã€Numexpr (è¡¨è¾¾å¼åŠ é€Ÿ)ã€Bottleneck (æ»šåŠ¨ç»Ÿè®¡)
2. **MLå¢å¼º**: LightGBMã€Category Encodersã€scikit-optimize (è´å¶æ–¯ä¼˜åŒ–)
3. **å·¥å…·å®Œå–„**: tqdmè¿›åº¦æ¡ã€joblibç¼“å­˜ã€aiofileså¼‚æ­¥IO
4. **æœºæ¢°ç¡¬ç›˜ä¼˜åŒ–**: Featheræ ¼å¼æŒ‡å—ã€åˆ†å—å¤„ç†ç­–ç•¥ã€å†…å­˜å¤–è®¡ç®—
5. **åº“ç‰ˆæœ¬å‡çº§**: scikit-learnå‡çº§åˆ°1.5.0ï¼Œpandas 2.2.2

### **v2.4 ä¸»è¦åŠŸèƒ½**
- æ–‡æœ¬åˆ†æèƒ½åŠ› (BeautifulSoup4 + lxml)
- å›¾è¡¨è‡ªåŠ¨æ•è·ç³»ç»Ÿå®Œå–„
- ä¼šè¯æ–‡ä»¶ç®¡ç†ä¼˜åŒ–

### **v2.3 åŠæ›´æ—©**
- åŸºç¡€æ²™ç›’åŠŸèƒ½
- å›¾è¡¨è‡ªåŠ¨æ•è·
- æ–‡ä»¶ä¸Šä¼ æ”¯æŒ

---

## ğŸ¯ **å¿«é€Ÿå¼€å§‹æ¨¡æ¿**

### **æ¨¡æ¿1: åŸºç¡€æ•°æ®åˆ†æ**
```python
import pandas as pd
import matplotlib.pyplot as plt

# 1. è¯»å–æ•°æ®
df = pd.read_csv('/data/data.csv')

# 2. å¿«é€Ÿåˆ†æ
print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
print(df.describe())

# 3. ç®€å•å¯è§†åŒ–
df.groupby('category')['value'].mean().plot(kind='bar')
plt.title('å„åˆ†ç±»å¹³å‡å€¼')
plt.tight_layout()
plt.show()
```

### **æ¨¡æ¿2: å®Œæ•´æŠ¥å‘Šç”Ÿæˆ**
```python
# å‚è€ƒ: report_generator_workflow.md
# åŒ…å«æ•°æ®è¯»å–ã€åˆ†æã€å›¾è¡¨ã€æ–‡æ¡£ç”Ÿæˆå…¨æµç¨‹

import pandas as pd
import matplotlib.pyplot as plt
from docx import Document
import base64, json

# 1. æ•°æ®è¯»å–ä¸åˆ†æ
df = pd.read_excel('/data/sales_data.xlsx')
summary = df.groupby('region')['sales'].sum()

# 2. åˆ›å»ºå›¾è¡¨
summary.plot(kind='bar')
plt.title('å„åœ°åŒºé”€å”®æ€»é¢')
plt.tight_layout()
plt.show()

# 3. ç”ŸæˆWordæŠ¥å‘Š
doc = Document()
doc.add_heading('é”€å”®åˆ†ææŠ¥å‘Š', 0)
doc.add_paragraph(f"æ€»é”€å”®é¢: ${df['sales'].sum():,.2f}")
doc.add_paragraph(f"å¹³å‡é”€å”®é¢: ${df['sales'].mean():,.2f}")

# 4. ä¿å­˜å¹¶è¾“å‡º
doc.save('/data/report.docx')
with open('/data/report.docx', 'rb') as f:
    file_data = base64.b64encode(f.read()).decode('utf-8')

output = {
    "type": "word",
    "title": "é”€å”®åˆ†ææŠ¥å‘Š.docx",
    "data_base64": file_data
}
print(json.dumps(output))
```

### **æ¨¡æ¿3: æœºå™¨å­¦ä¹ å»ºæ¨¡**
```python
# å‚è€ƒ: ml_workflow.md
# åŒ…å«æ•°æ®é¢„å¤„ç†ã€ç‰¹å¾å·¥ç¨‹ã€æ¨¡å‹è®­ç»ƒã€è¯„ä¼°

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# 1. åŠ è½½æ•°æ®
df = pd.read_csv('/data/iris.csv')

# 2. ç‰¹å¾ä¸æ ‡ç­¾
X = df.drop('species', axis=1)
y = df['species']

# 3. åˆ’åˆ†æ•°æ®é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 4. è®­ç»ƒæ¨¡å‹
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 5. è¯„ä¼°
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))
```

---

## ğŸ’¡ **ç»ˆææç¤º**

1. **ä¼˜å…ˆæŸ¥é˜…å‚è€ƒæ–‡ä»¶** - ä¸è¦é‡æ–°å‘æ˜è½®å­
2. **åˆ©ç”¨ä¼šè¯æŒä¹…åŒ–** - ä¿å­˜ä¸­é—´ç»“æœï¼Œåˆ†æ­¥æ‰§è¡Œå¤æ‚ä»»åŠ¡
3. **ä¿¡ä»»è‡ªåŠ¨åŒ–ç³»ç»Ÿ** - å›¾è¡¨ã€è¾“å‡ºæ ¼å¼ç­‰äº¤ç»™åç«¯å¤„ç†
4. **æ€§èƒ½æ•æ„Ÿç”¨ä¼˜åŒ–åº“** - å¤§æ–‡ä»¶ç”¨DuckDBï¼Œå¤æ‚è®¡ç®—ç”¨Numexpr
5. **æµ‹è¯•ä»£ç ç‰‡æ®µ** - å¤æ‚é€»è¾‘å…ˆå°è§„æ¨¡æµ‹è¯•
6. **æœºæ¢°ç¡¬ç›˜ä¼˜åŒ–** - ä½¿ç”¨Featheræ ¼å¼ã€å¼‚æ­¥IOã€å†…å­˜å¤–è®¡ç®—
7. **æ–°åº“ç›´æ¥ä½¿ç”¨** - v2.5æ–°å¢åº“æ— éœ€ç‰¹æ®Šé…ç½®ï¼Œç›´æ¥å¯¼å…¥
8. **å†…å­˜ç®¡ç†** - åŠæ—¶åˆ é™¤å¤§å˜é‡ï¼Œä½¿ç”¨åˆ†å—å¤„ç†é¿å…OOM

---

## ğŸ”— **ç›¸å…³èµ„æº**

- **å®Œæ•´ç¤ºä¾‹åº“**: æ‰€æœ‰å‚è€ƒæ–‡ä»¶ä¸­çš„ä»£ç ç¤ºä¾‹
- **æ€§èƒ½æµ‹è¯•**: å¯¹æ¯”ä¸åŒæ–¹æ³•çš„æ‰§è¡Œæ•ˆç‡
- **æœ€ä½³å®è·µ**: å„é¢†åŸŸçš„æ ‡å‡†åŒ–å·¥ä½œæµ
- **æ•…éšœæ¡ˆä¾‹**: å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

**è®°ä½**: è¿™ä¸ªæ²™ç›’ç¯å¢ƒå·²ç»é¢„é…ç½®äº†æ‰€æœ‰åº“å’Œä¼˜åŒ–ï¼Œä½ åªéœ€è¦ä¸“æ³¨äºä¸šåŠ¡é€»è¾‘ï¼ç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†æŠ€æœ¯ç»†èŠ‚ï¼Œè®©ä½ åƒåœ¨æœ¬åœ°ç¯å¢ƒä¸€æ ·é¡ºç•…å·¥ä½œã€‚
