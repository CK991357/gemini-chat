# Pandas æ•°æ®å¤„ç†é€ŸæŸ¥è¡¨

## ğŸ”§ å¸¸ç”¨æ“ä½œé€ŸæŸ¥

### æ•°æ®è¯»å–ä¸æŸ¥çœ‹
```python
import pandas as pd
import numpy as np

# åˆ›å»ºç¤ºä¾‹æ•°æ®
df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Charlie', 'David'],
    'Age': [25, 30, 35, 28],
    'Salary': [50000, 60000, 70000, 55000],
    'Department': ['IT', 'HR', 'IT', 'Finance']
})

# åŸºæœ¬æŸ¥çœ‹
df.head()        # å‰5è¡Œ
df.info()        # æ•°æ®ä¿¡æ¯
df.describe()    # æ•°å€¼åˆ—ç»Ÿè®¡
df.shape         # æ•°æ®ç»´åº¦
```

### æ•°æ®æ¸…æ´—æ¨¡æ¿
```python
def data_cleaning_pipeline(df):
    """å®Œæ•´çš„æ•°æ®æ¸…æ´—æµæ°´çº¿"""
    
    # 1. å¤„ç†ç¼ºå¤±å€¼
    print("å¤„ç†å‰ç¼ºå¤±å€¼ç»Ÿè®¡:")
    print(df.isnull().sum())
    
    # æ•°å€¼åˆ—ç”¨ä¸­ä½æ•°å¡«å……
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())
    
    # åˆ†ç±»åˆ—ç”¨ä¼—æ•°å¡«å……
    categorical_cols = df.select_dtypes(include=['object']).columns
    for col in categorical_cols:
        df[col] = df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else 'Unknown')
    
    # 2. å¤„ç†å¼‚å¸¸å€¼ï¼ˆIQRæ–¹æ³•ï¼‰
    def remove_outliers_iqr(df, column):
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]
    
    for col in numeric_cols:
        df = remove_outliers_iqr(df, col)
    
    # 3. æ•°æ®ç±»å‹è½¬æ¢
    df['Age'] = df['Age'].astype(int)
    
    return df
```

### æ•°æ®è½¬æ¢æ“ä½œ
```python
# æ•°æ®ç­›é€‰
df_filtered = df[df['Age'] > 25]
df_department = df[df['Department'].isin(['IT', 'Finance'])]

# æ•°æ®æ’åº
df_sorted = df.sort_values(['Department', 'Salary'], ascending=[True, False])

# åˆ†ç»„èšåˆ
department_stats = df.groupby('Department').agg({
    'Age': ['mean', 'min', 'max'],
    'Salary': ['mean', 'sum', 'count']
}).round(2)

# æ•°æ®é€è§†è¡¨
pivot_table = pd.pivot_table(df, 
                           values='Salary', 
                           index='Department', 
                           columns=None, 
                           aggfunc=['mean', 'sum'])
```

## ğŸ“Š å®Œæ•´æ•°æ®æ¸…æ´—æµæ°´çº¿

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import io
import base64
import json

def comprehensive_data_analysis(df):
    """å®Œæ•´çš„æ•°æ®åˆ†æä¸æ¸…æ´—æµæ°´çº¿"""
    
    # æ•°æ®è´¨é‡æŠ¥å‘Š
    quality_report = {
        'original_rows': len(df),
        'original_columns': len(df.columns),
        'missing_values': df.isnull().sum().to_dict(),
        'data_types': df.dtypes.astype(str).to_dict(),
        'duplicate_rows': df.duplicated().sum()
    }
    
    # æ•°æ®æ¸…æ´—
    df_clean = df.copy()
    
    # 1. å¤„ç†ç¼ºå¤±å€¼
    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns
    categorical_cols = df_clean.select_dtypes(include=['object']).columns
    
    for col in numeric_cols:
        df_clean[col].fillna(df_clean[col].median(), inplace=True)
    
    for col in categorical_cols:
        df_clean[col].fillna(df_clean[col].mode()[0] if not df_clean[col].mode().empty else 'Unknown', inplace=True)
    
    # 2. å¤„ç†å¼‚å¸¸å€¼
    outliers_removed = 0
    for col in numeric_cols:
        Q1 = df_clean[col].quantile(0.25)
        Q3 = df_clean[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        before = len(df_clean)
        df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]
        outliers_removed += (before - len(df_clean))
    
    quality_report['cleaned_rows'] = len(df_clean)
    quality_report['outliers_removed'] = outliers_removed
    
    # 3. ç»Ÿè®¡åˆ†æ
    analysis_results = {
        'descriptive_stats': df_clean.describe().to_dict(),
        'correlation_matrix': df_clean.select_dtypes(include=[np.number]).corr().to_dict()
    }
    
    # 4. ç”Ÿæˆå¯è§†åŒ–
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # æ•°å€¼åˆ—åˆ†å¸ƒ
    if len(numeric_cols) > 0:
        df_clean[numeric_cols[0]].hist(ax=axes[0,0], bins=15, alpha=0.7, edgecolor='black')
        axes[0,0].set_title(f'{numeric_cols[0]}åˆ†å¸ƒ')
    
    # ç®±çº¿å›¾
    if len(numeric_cols) > 0:
        df_clean[numeric_cols].boxplot(ax=axes[0,1])
        axes[0,1].set_title('æ•°å€¼åˆ—ç®±çº¿å›¾')
    
    # ç›¸å…³æ€§çƒ­åŠ›å›¾
    if len(numeric_cols) > 1:
        sns.heatmap(df_clean[numeric_cols].corr(), annot=True, cmap='coolwarm', ax=axes[1,0])
        axes[1,0].set_title('ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾')
    
    # åˆ†ç±»æ•°æ®ç»Ÿè®¡
    if len(categorical_cols) > 0:
        df_clean[categorical_cols[0]].value_counts().plot(kind='bar', ax=axes[1,1])
        axes[1,1].set_title(f'{categorical_cols[0]}åˆ†å¸ƒ')
        axes[1,1].tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    
    # è¾“å‡ºå›¾è¡¨
    buf = io.BytesIO()
    plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')
    buf.seek(0)
    chart_base64 = base64.b64encode(buf.read()).decode('utf-8')
    buf.close()
    plt.close('all')
    
    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    result = {
        "type": "analysis_report",
        "title": "æ•°æ®æ¸…æ´—ä¸åˆ†ææŠ¥å‘Š",
        "data_quality": quality_report,
        "statistical_analysis": analysis_results,
        "chart_preview": chart_base64,
        "cleaned_data_sample": df_clean.head().to_dict('records')
    }
    print(json.dumps(result))

# ä½¿ç”¨ç¤ºä¾‹
# data = {'Age': [25, 30, 35, 28, np.nan], 'Salary': [50000, 60000, 70000, 55000, 1000000]}
# df = pd.DataFrame(data)
# comprehensive_data_analysis(df)
```

## ğŸš€ é«˜çº§æ•°æ®å¤„ç†æŠ€å·§

### æ•°æ®åˆå¹¶ä¸è¿æ¥
```python
# åˆå¹¶å¤šä¸ªDataFrame
df1 = pd.DataFrame({'A': ['A0', 'A1'], 'B': ['B0', 'B1']})
df2 = pd.DataFrame({'A': ['A0', 'A2'], 'C': ['C0', 'C2']})

# å†…è¿æ¥
result_inner = pd.merge(df1, df2, on='A', how='inner')

# å·¦è¿æ¥
result_left = pd.merge(df1, df2, on='A', how='left')

# å¤–è¿æ¥
result_outer = pd.merge(df1, df2, on='A', how='outer')
```

### æ—¶é—´åºåˆ—å¤„ç†
```python
# åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
dates = pd.date_range('2024-01-01', periods=100, freq='D')
ts_data = pd.DataFrame({
    'date': dates,
    'value': np.random.randn(100).cumsum()
})

# è®¾ç½®æ—¶é—´ç´¢å¼•
ts_data.set_index('date', inplace=True)

# é‡é‡‡æ ·ï¼ˆæ—¥æ•°æ®è½¬ä¸ºå‘¨æ•°æ®ï¼‰
weekly_data = ts_data.resample('W').mean()

# ç§»åŠ¨å¹³å‡
ts_data['moving_avg'] = ts_data['value'].rolling(window=7).mean()
```

è¿™ä¸ªé€ŸæŸ¥è¡¨æä¾›äº†ä»åŸºç¡€åˆ°é«˜çº§çš„Pandasæ“ä½œæŒ‡å—ï¼Œæ˜¯æ•°æ®å¤„ç†ä»»åŠ¡çš„å¿…å¤‡å‚è€ƒã€‚
