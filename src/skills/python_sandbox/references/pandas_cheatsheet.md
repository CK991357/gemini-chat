# Pandas æ•°æ®å¤„ç†æŒ‡å— (v2.2)

## ğŸ¯ å·¥å…·æ¦‚è¿°
**åŠŸèƒ½**ï¼šæ•°æ®æ¸…æ´—ã€è½¬æ¢ã€åˆ†æå’Œå¯è§†åŒ–
**è¾“å‡ºåŸåˆ™**ï¼šç›´æ¥æ‰“å°ç»“æœï¼Œç³»ç»Ÿè‡ªåŠ¨å¤„ç†è¾“å‡ºæ ¼å¼

## ğŸ”§ åŸºç¡€æ•°æ®æ“ä½œ

### æ•°æ®åˆ›å»ºä¸æŸ¥çœ‹
```python
import pandas as pd
import numpy as np

# åˆ›å»ºç¤ºä¾‹æ•°æ®
df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],
    'Age': [25, 30, 35, 28, 32],
    'Salary': [50000, 60000, 70000, 55000, 65000],
    'Department': ['IT', 'HR', 'IT', 'Finance', 'Marketing'],
    'Join_Date': pd.date_range('2020-01-01', periods=5, freq='Y')
})

print("=== æ•°æ®åŸºæœ¬ä¿¡æ¯ ===")
print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
print(f"åˆ—å: {list(df.columns)}")
print("\nå‰5è¡Œæ•°æ®:")
print(df.head())
print("\næ•°æ®ä¿¡æ¯:")
print(df.info())
print("\næ•°å€¼åˆ—ç»Ÿè®¡:")
print(df.describe())
```

### æ•°æ®ç­›é€‰ä¸æ’åº
```python
import pandas as pd

# å‡è®¾dfæ˜¯å·²æœ‰çš„DataFrame
print("=== æ•°æ®ç­›é€‰ä¸æ’åº ===")

# æ¡ä»¶ç­›é€‰
age_above_30 = df[df['Age'] > 30]
print(f"å¹´é¾„å¤§äº30çš„å‘˜å·¥: {len(age_above_30)}äºº")
print(age_above_30[['Name', 'Age', 'Department']])

# å¤šæ¡ä»¶ç­›é€‰
it_high_salary = df[(df['Department'] == 'IT') & (df['Salary'] > 55000)]
print(f"\nITéƒ¨é—¨é«˜è–ªå‘˜å·¥:")
print(it_high_salary[['Name', 'Salary']])

# æ•°æ®æ’åº
sorted_by_salary = df.sort_values('Salary', ascending=False)
print(f"\næŒ‰è–ªèµ„é™åºæ’åˆ—:")
print(sorted_by_salary[['Name', 'Salary', 'Department']])
```

## ğŸ§¹ æ•°æ®æ¸…æ´—æ¨¡æ¿

### åŸºç¡€æ•°æ®æ¸…æ´—
```python
import pandas as pd
import numpy as np

def basic_data_cleaning(df):
    """åŸºç¡€æ•°æ®æ¸…æ´—æµç¨‹"""
    
    print("=== æ•°æ®æ¸…æ´—æµç¨‹ ===")
    df_clean = df.copy()
    
    # 1. æ£€æŸ¥æ•°æ®è´¨é‡
    print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {df_clean.shape}")
    print(f"ç¼ºå¤±å€¼ç»Ÿè®¡:")
    print(df_clean.isnull().sum())
    print(f"é‡å¤è¡Œæ•°: {df_clean.duplicated().sum()}")
    
    # 2. å¤„ç†ç¼ºå¤±å€¼
    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns
    categorical_cols = df_clean.select_dtypes(include=['object']).columns
    
    # æ•°å€¼åˆ—ç”¨ä¸­ä½æ•°å¡«å……
    for col in numeric_cols:
        if df_clean[col].isnull().any():
            median_val = df_clean[col].median()
            df_clean[col].fillna(median_val, inplace=True)
            print(f"åˆ— '{col}' ç”¨ä¸­ä½æ•° {median_val} å¡«å……ç¼ºå¤±å€¼")
    
    # åˆ†ç±»åˆ—ç”¨ä¼—æ•°å¡«å……
    for col in categorical_cols:
        if df_clean[col].isnull().any():
            mode_val = df_clean[col].mode()[0] if not df_clean[col].mode().empty else 'Unknown'
            df_clean[col].fillna(mode_val, inplace=True)
            print(f"åˆ— '{col}' ç”¨ä¼—æ•° '{mode_val}' å¡«å……ç¼ºå¤±å€¼")
    
    # 3. åˆ é™¤é‡å¤è¡Œ
    before_dedup = len(df_clean)
    df_clean = df_clean.drop_duplicates()
    after_dedup = len(df_clean)
    print(f"åˆ é™¤é‡å¤è¡Œ: {before_dedup - after_dedup} è¡Œ")
    
    print(f"\næ¸…æ´—åæ•°æ®å½¢çŠ¶: {df_clean.shape}")
    return df_clean

# ä½¿ç”¨ç¤ºä¾‹
# df_with_issues = pd.DataFrame({
#     'A': [1, 2, np.nan, 4, 4],
#     'B': ['x', 'y', np.nan, 'x', 'z']
# })
# cleaned_df = basic_data_cleaning(df_with_issues)
```

### å¼‚å¸¸å€¼å¤„ç†
```python
import pandas as pd
import numpy as np

def handle_outliers(df):
    """å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†"""
    
    print("=== å¼‚å¸¸å€¼å¤„ç† ===")
    df_clean = df.copy()
    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns
    
    outliers_info = {}
    
    for col in numeric_cols:
        Q1 = df_clean[col].quantile(0.25)
        Q3 = df_clean[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        # æ£€æµ‹å¼‚å¸¸å€¼
        outliers = df_clean[(df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)]
        outlier_count = len(outliers)
        
        if outlier_count > 0:
            print(f"åˆ— '{col}' å‘ç° {outlier_count} ä¸ªå¼‚å¸¸å€¼")
            print(f"  èŒƒå›´: [{lower_bound:.2f}, {upper_bound:.2f}]")
            print(f"  å¼‚å¸¸å€¼: {outliers[col].tolist()}")
            
            # ç”¨è¾¹ç•Œå€¼æ›¿æ¢å¼‚å¸¸å€¼ï¼ˆå¯é€‰ï¼‰
            df_clean[col] = np.where(df_clean[col] < lower_bound, lower_bound, df_clean[col])
            df_clean[col] = np.where(df_clean[col] > upper_bound, upper_bound, df_clean[col])
    
    return df_clean

# ä½¿ç”¨ç¤ºä¾‹
# df_with_outliers = pd.DataFrame({'Values': [1, 2, 3, 100, 2, 3, 1, -50]})
# cleaned_df = handle_outliers(df_with_outliers)
```

## ğŸ“Š æ•°æ®åˆ†æä¸ç»Ÿè®¡

### åˆ†ç»„ç»Ÿè®¡
```python
import pandas as pd

# å‡è®¾dfæ˜¯å·²æœ‰çš„DataFrame
print("=== åˆ†ç»„ç»Ÿè®¡åˆ†æ ===")

# åŸºç¡€åˆ†ç»„ç»Ÿè®¡
dept_stats = df.groupby('Department').agg({
    'Age': ['mean', 'min', 'max', 'count'],
    'Salary': ['mean', 'sum', 'std']
}).round(2)

print("å„éƒ¨é—¨ç»Ÿè®¡:")
print(dept_stats)

# æ›´è¯¦ç»†çš„åˆ†ç»„åˆ†æ
print("\nå„éƒ¨é—¨è¯¦ç»†åˆ†æ:")
for dept, group in df.groupby('Department'):
    print(f"\n{dept}éƒ¨é—¨:")
    print(f"  å‘˜å·¥æ•°: {len(group)}")
    print(f"  å¹³å‡å¹´é¾„: {group['Age'].mean():.1f}")
    print(f"  å¹³å‡è–ªèµ„: {group['Salary'].mean():.0f}")
    print(f"  æ€»è–ªèµ„: {group['Salary'].sum():.0f}")
```

### æ•°æ®é€è§†è¡¨
```python
import pandas as pd

print("=== æ•°æ®é€è§†è¡¨ ===")

# åˆ›å»ºæ›´ä¸°å¯Œçš„æ•°æ®ç”¨äºæ¼”ç¤º
sales_data = pd.DataFrame({
    'Region': ['North', 'South', 'East', 'West'] * 6,
    'Product': ['A', 'B'] * 12,
    'Quarter': ['Q1', 'Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2', 'Q2', 'Q3', 'Q3', 'Q3', 'Q3'] * 2,
    'Sales': np.random.randint(1000, 5000, 24),
    'Profit': np.random.randint(100, 1000, 24)
})

# åŸºç¡€æ•°æ®é€è§†è¡¨
pivot1 = pd.pivot_table(sales_data, 
                       values='Sales', 
                       index='Region', 
                       columns='Quarter', 
                       aggfunc='sum')

print("å„åœ°åŒºå„å­£åº¦é”€å”®æ€»é¢:")
print(pivot1)

# å¤šæŒ‡æ ‡æ•°æ®é€è§†è¡¨
pivot2 = pd.pivot_table(sales_data,
                       values=['Sales', 'Profit'],
                       index=['Region', 'Product'],
                       columns='Quarter',
                       aggfunc={'Sales': 'sum', 'Profit': 'mean'})

print("\nå„åœ°åŒºäº§å“è¯¦ç»†åˆ†æ:")
print(pivot2)
```

## ğŸ“ˆ æ•°æ®å¯è§†åŒ–

### åŸºç¡€å›¾è¡¨
```python
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

print("=== æ•°æ®å¯è§†åŒ– ===")

# åˆ›å»ºç¤ºä¾‹æ•°æ®
sales_data = pd.DataFrame({
    'Month': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun'],
    'Sales': [120, 150, 130, 170, 160, 190],
    'Profit': [40, 50, 45, 60, 55, 70]
})

# æŠ˜çº¿å›¾
plt.figure(figsize=(10, 6))
plt.plot(sales_data['Month'], sales_data['Sales'], marker='o', label='Sales', linewidth=2)
plt.plot(sales_data['Month'], sales_data['Profit'], marker='s', label='Profit', linewidth=2)
plt.title('æœˆåº¦é”€å”®ä¸åˆ©æ¶¦è¶‹åŠ¿')
plt.xlabel('æœˆä»½')
plt.ylabel('é‡‘é¢ (åƒå…ƒ)')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# æ¡å½¢å›¾
plt.figure(figsize=(10, 6))
plt.bar(sales_data['Month'], sales_data['Sales'], alpha=0.7, label='Sales')
plt.title('æœˆåº¦é”€å”®é¢')
plt.xlabel('æœˆä»½')
plt.ylabel('é”€å”®é¢ (åƒå…ƒ)')
plt.tight_layout()
plt.show()
```

### é«˜çº§å¯è§†åŒ–
```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# åˆ›å»ºç›¸å…³æ•°æ®ç¤ºä¾‹
data = pd.DataFrame({
    'Feature1': np.random.normal(0, 1, 100),
    'Feature2': np.random.normal(0, 1, 100),
    'Feature3': np.random.normal(0, 1, 100),
    'Target': np.random.normal(0, 1, 100)
})

# ç›¸å…³æ€§çƒ­åŠ›å›¾
plt.figure(figsize=(8, 6))
correlation_matrix = data.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾')
plt.tight_layout()
plt.show()

# åˆ†å¸ƒç›´æ–¹å›¾
plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
data['Feature1'].hist(bins=15, alpha=0.7, edgecolor='black')
plt.title('Feature1 åˆ†å¸ƒ')

plt.subplot(1, 3, 2)
data['Feature2'].hist(bins=15, alpha=0.7, edgecolor='black')
plt.title('Feature2 åˆ†å¸ƒ')

plt.subplot(1, 3, 3)
data['Feature3'].hist(bins=15, alpha=0.7, edgecolor='black')
plt.title('Feature3 åˆ†å¸ƒ')

plt.tight_layout()
plt.show()
```

## ğŸš€ é«˜çº§æ•°æ®å¤„ç†

### æ—¶é—´åºåˆ—åˆ†æ
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

print("=== æ—¶é—´åºåˆ—åˆ†æ ===")

# åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
dates = pd.date_range('2024-01-01', periods=100, freq='D')
time_series = pd.DataFrame({
    'date': dates,
    'value': np.random.randn(100).cumsum() + 100,
    'volume': np.random.randint(100, 1000, 100)
})

# è®¾ç½®æ—¶é—´ç´¢å¼•
time_series.set_index('date', inplace=True)

print("æ—¶é—´åºåˆ—åŸºæœ¬ä¿¡æ¯:")
print(f"æ—¶é—´èŒƒå›´: {time_series.index.min()} åˆ° {time_series.index.max()}")
print(f"æ•°æ®ç‚¹æ•°: {len(time_series)}")

# é‡é‡‡æ ·ï¼ˆæ—¥æ•°æ®è½¬ä¸ºå‘¨æ•°æ®ï¼‰
weekly_data = time_series.resample('W').agg({'value': 'mean', 'volume': 'sum'})
print("\nå‘¨åº¦èšåˆæ•°æ®:")
print(weekly_data.head())

# ç§»åŠ¨å¹³å‡
time_series['7_day_ma'] = time_series['value'].rolling(window=7).mean()

# å¯è§†åŒ–æ—¶é—´åºåˆ—
plt.figure(figsize=(12, 8))

plt.subplot(2, 1, 1)
plt.plot(time_series.index, time_series['value'], label='åŸå§‹å€¼', alpha=0.7)
plt.plot(time_series.index, time_series['7_day_ma'], label='7æ—¥ç§»åŠ¨å¹³å‡', linewidth=2)
plt.title('æ—¶é—´åºåˆ—ä¸ç§»åŠ¨å¹³å‡')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(2, 1, 2)
plt.bar(weekly_data.index, weekly_data['volume'], alpha=0.7)
plt.title('å‘¨åº¦äº¤æ˜“é‡')
plt.tight_layout()
plt.show()
```

### æ•°æ®åˆå¹¶ä¸è¿æ¥
```python
import pandas as pd

print("=== æ•°æ®åˆå¹¶æ“ä½œ ===")

# åˆ›å»ºç¤ºä¾‹æ•°æ®
df1 = pd.DataFrame({
    'ID': [1, 2, 3, 4],
    'Name': ['Alice', 'Bob', 'Charlie', 'David'],
    'Dept': ['IT', 'HR', 'IT', 'Finance']
})

df2 = pd.DataFrame({
    'ID': [1, 2, 5, 6],
    'Salary': [50000, 60000, 70000, 55000],
    'Join_Date': ['2020-01-01', '2019-03-15', '2021-06-01', '2018-11-20']
})

print("æ•°æ®è¡¨1:")
print(df1)
print("\næ•°æ®è¡¨2:")
print(df2)

# å†…è¿æ¥
inner_join = pd.merge(df1, df2, on='ID', how='inner')
print(f"\nå†…è¿æ¥ç»“æœ (å…±{len(inner_join)}è¡Œ):")
print(inner_join)

# å·¦è¿æ¥
left_join = pd.merge(df1, df2, on='ID', how='left')
print(f"\nå·¦è¿æ¥ç»“æœ (å…±{len(left_join)}è¡Œ):")
print(left_join)

# å¤–è¿æ¥
outer_join = pd.merge(df1, df2, on='ID', how='outer')
print(f"\nå¤–è¿æ¥ç»“æœ (å…±{len(outer_join)}è¡Œ):")
print(outer_join)
```

## âš ï¸ ä½¿ç”¨æ³¨æ„äº‹é¡¹

### âœ… æ¨èåšæ³•ï¼š
- æ­£å¸¸å¯¼å…¥ï¼š`import pandas as pd`
- ä½¿ç”¨æ ‡å‡†çš„ Pandas å‡½æ•°å’Œæ–¹æ³•
- ç›´æ¥ä½¿ç”¨ `print()` è¾“å‡ºç»“æœ
- ä½¿ç”¨ `plt.show()` æ˜¾ç¤ºå›¾è¡¨

### âŒ é¿å…çš„æ“ä½œï¼š
- ä¸è¦æ‰‹åŠ¨æ„å»º JSON è¾“å‡º
- ä¸è¦ä½¿ç”¨ `base64` ç¼–ç å›¾åƒ
- ä¸è¦åˆ›å»ºå¤æ‚çš„è‡ªå®šä¹‰è¾“å‡ºæ ¼å¼

### ğŸ”§ é”™è¯¯å¤„ç†ï¼š
```python
try:
    import pandas as pd
    # æ•°æ®å¤„ç†ä»£ç 
    result = df.groupby('Department')['Salary'].mean()
    print(f"å„éƒ¨é—¨å¹³å‡è–ªèµ„: {result}")
except ImportError:
    print("Pandas ä¸å¯ç”¨")
except Exception as e:
    print(f"æ•°æ®å¤„ç†é”™è¯¯: {e}")
```

### ğŸ’¡ å®ç”¨æŠ€å·§ï¼š
```python
# å¿«é€ŸæŸ¥çœ‹æ•°æ®åˆ†å¸ƒ
def quick_analysis(df):
    print("æ•°æ®å¿«é€Ÿåˆ†æ:")
    print(f"å½¢çŠ¶: {df.shape}")
    print(f"å†…å­˜ä½¿ç”¨: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
    print("\næ•°å€¼åˆ—ç»Ÿè®¡:")
    print(df.describe())
    print("\nç¼ºå¤±å€¼ç»Ÿè®¡:")
    print(df.isnull().sum())

# ä½¿ç”¨ç¤ºä¾‹
# quick_analysis(your_dataframe)
```

**è®°ä½**ï¼šç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†æ‰€æœ‰è¾“å‡ºæ ¼å¼ï¼Œæ‚¨åªéœ€è¦ä¸“æ³¨äºæ•°æ®å¤„ç†é€»è¾‘ï¼
