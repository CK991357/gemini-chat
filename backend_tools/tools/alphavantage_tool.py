"""AlphaVantageé‡‘èæ•°æ®è·å–å·¥å…· - æœ€ç»ˆä¼˜åŒ–ç‰ˆæœ¬"""
import os
import logging
import json
import asyncio
import pandas as pd
import requests
from pathlib import Path
from typing import Dict, Any, List, Optional, Union, Literal
from pydantic import BaseModel, Field
from datetime import datetime
from enum import Enum
from tenacity import retry, stop_after_attempt, wait_exponential

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# ==================== é…ç½®åŒº ====================
SESSION_WORKSPACE_ROOT = Path("/srv/sandbox_workspaces")
SESSION_TIMEOUT_HOURS = 24

# ==================== æšä¸¾å®šä¹‰ ====================
class AlphaVantageMode(str, Enum):
    """AlphaVantageåŠŸèƒ½æ¨¡å¼ - 13ä¸ªå®Œæ•´åŠŸèƒ½"""
    WEEKLY_ADJUSTED = "weekly_adjusted"
    GLOBAL_QUOTE = "global_quote"
    HISTORICAL_OPTIONS = "historical_options"
    EARNINGS_TRANSCRIPT = "earnings_transcript"
    INSIDER_TRANSACTIONS = "insider_transactions"
    ETF_PROFILE = "etf_profile"
    FOREX_DAILY = "forex_daily"
    DIGITAL_CURRENCY_DAILY = "digital_currency_daily"
    WTI = "wti"
    BRENT = "brent"
    COPPER = "copper"
    TREASURY_YIELD = "treasury_yield"
    NEWS_SENTIMENT = "news_sentiment"

# ==================== å‚æ•°æ¨¡å‹ ====================
class WeeklyAdjustedParams(BaseModel):
    symbol: str = Field(description="è‚¡ç¥¨ä»£ç ï¼Œå¦‚ï¼šAAPL, MSFT")

class GlobalQuoteParams(BaseModel):
    symbol: str = Field(description="è‚¡ç¥¨ä»£ç ï¼Œå¦‚ï¼šAAPL, MSFT")

class HistoricalOptionsParams(BaseModel):
    symbol: str = Field(description="è‚¡ç¥¨ä»£ç ï¼Œå¦‚ï¼šAAPL")
    date: Optional[str] = Field(default=None, description="æœŸæƒåˆ°æœŸæ—¥ï¼Œæ ¼å¼ï¼šYYYY-MM-DD")

class EarningsTranscriptParams(BaseModel):
    symbol: str = Field(description="è‚¡ç¥¨ä»£ç ï¼Œå¦‚ï¼šAAPL")
    quarter: str = Field(description="å­£åº¦ï¼Œæ ¼å¼ï¼šYYYY-Q1/Q2/Q3/Q4")

class InsiderTransactionsParams(BaseModel):
    symbol: str = Field(description="è‚¡ç¥¨ä»£ç ï¼Œå¦‚ï¼šAAPL")

class ETFProfileParams(BaseModel):
    symbol: str = Field(description="ETFä»£ç ï¼Œå¦‚ï¼šSPY, QQQ")

class ForexDailyParams(BaseModel):
    from_symbol: str = Field(default="USD", description="æºè´§å¸ä»£ç ï¼Œå¦‚ï¼šUSD")
    to_symbol: str = Field(default="JPY", description="ç›®æ ‡è´§å¸ä»£ç ï¼Œå¦‚ï¼šJPY")
    outputsize: Literal["compact", "full"] = Field(default="full", description="æ•°æ®å¤§å°")

class DigitalCurrencyDailyParams(BaseModel):
    symbol: str = Field(description="æ•°å­—è´§å¸ä»£ç ï¼Œå¦‚ï¼šBTC")
    market: str = Field(description="äº¤æ˜“å¸‚åœºï¼Œå¦‚ï¼šUSD, CNY")

class CommodityParams(BaseModel):
    interval: Literal["daily", "weekly", "monthly"] = Field(default="monthly", description="æ•°æ®é—´éš”")

class TreasuryYieldParams(BaseModel):
    interval: Literal["daily", "weekly", "monthly"] = Field(default="monthly", description="æ•°æ®é—´éš”")
    maturity: str = Field(default="10year", description="å›½å€ºæœŸé™ï¼Œå¦‚ï¼š3month, 2year, 10year")

class NewsSentimentParams(BaseModel):
    tickers: Optional[str] = Field(default=None, description="è‚¡ç¥¨ä»£ç ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš”")
    topics: Optional[str] = Field(default=None, description="ä¸»é¢˜ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš”")
    time_from: Optional[str] = Field(default=None, description="å¼€å§‹æ—¶é—´ï¼Œæ ¼å¼ï¼šYYYYMMDDTHHMM")
    time_to: Optional[str] = Field(default=None, description="ç»“æŸæ—¶é—´ï¼Œæ ¼å¼ï¼šYYYYMMDDTHHMM")
    sort: Literal["LATEST", "EARLIEST", "RELEVANCE"] = Field(default="LATEST", description="æ’åºæ–¹å¼")
    limit: int = Field(default=50, ge=1, le=1000, description="è¿”å›æ•°é‡é™åˆ¶")

# å·¥å…·è¾“å…¥æ¨¡å‹
class AlphaVantageInput(BaseModel):
    """AlphaVantageå·¥å…·è¾“å…¥æ¨¡å‹"""
    mode: AlphaVantageMode = Field(description="è¦æ‰§è¡Œçš„AlphaVantageåŠŸèƒ½æ¨¡å¼")
    parameters: Dict[str, Any] = Field(description="åŠŸèƒ½å‚æ•°")

# ==================== AlphaVantageæ•°æ®è·å–å™¨ ====================
class AlphaVantageFetcher:
    """AlphaVantageæ•°æ®è·å–å™¨ - å®Œæ•´ç‰ˆ"""
    
    BASE_URL = "https://www.alphavantage.co/query"
    
    @staticmethod
    def get_api_key():
        """ä»ç¯å¢ƒå˜é‡è·å–API Key"""
        key = os.getenv("ALPHAVANTAGE_API_KEY")
        if not key:
            logger.warning("âš ï¸ ALPHAVANTAGE_API_KEYæœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤key")
            return "U5KM36DHDXR95Q7Q"  # é»˜è®¤key
        return key
    
    # ============ è‚¡ç¥¨æ•°æ®æ–¹æ³• ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_weekly_adjusted(symbol: str, session_dir: Path = None) -> pd.DataFrame:
        """è·å–å‘¨è°ƒæ•´åæ•°æ®"""
        try:
            params = {
                "function": "TIME_SERIES_WEEKLY_ADJUSTED",
                "symbol": symbol, 
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            time_series = data.get("Weekly Adjusted Time Series", {})
            if not time_series:
                raise ValueError("No weekly data found in response")

            df = pd.DataFrame.from_dict(time_series, orient="index")
            df.index = pd.to_datetime(df.index)
            df = df.sort_index()

            df = df.rename(columns={
                "1. open": "open",
                "2. high": "high",
                "3. low": "low",
                "4. close": "close",
                "5. adjusted close": "adjusted_close",
                "6. volume": "volume",
                "7. dividend amount": "dividend"
            })

            df = df.astype({
                "open": float,
                "high": float,
                "low": float,
                "close": float,
                "adjusted_close": float,
                "volume": int,
                "dividend": float
            })

            # ğŸ¯ ä¿å­˜åˆ°ä¼šè¯ç›®å½•æ ¹ç›®å½•ï¼ˆä¿®æ”¹ï¼šå»æ‰å­ç›®å½•ï¼‰
            if session_dir:
                file_path = session_dir / f"stock_{symbol}.parquet"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                df.to_parquet(file_path)
                logger.info(f"è‚¡ç¥¨æ•°æ®å·²ä¿å­˜è‡³ä¼šè¯ç›®å½•ï¼š{file_path}")
            else:
                # åå¤‡ï¼šä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
                temp_dir = Path("/tmp/alphavantage_data") / "us_stock"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"stock_{symbol}.parquet"
                df.to_parquet(file_path)
                logger.info(f"è‚¡ç¥¨æ•°æ®å·²ä¿å­˜è‡³ä¸´æ—¶ç›®å½•ï¼š{file_path}")

            return df[["open", "high", "low", "close", "adjusted_close", "volume", "dividend"]]

        except Exception as e:
            logger.error(f"è·å–AlphaVantageæ•°æ®å¤±è´¥: {e}")
            raise
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_global_quote(symbol: str, session_dir: Path = None) -> Dict[str, Union[str, float, int]]:
        """è·å–å®æ—¶è¡Œæƒ…æ•°æ®"""
        try:
            params = {
                "function": "GLOBAL_QUOTE",
                "symbol": symbol,
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            quote = data.get("Global Quote", {})
            if not quote:
                raise ValueError("No quote data found in response")

            result = {
                'symbol': quote.get('01. symbol'),
                'open': float(quote.get('02. open', 0)) if quote.get('02. open', '') != '' else 0.0,
                'high': float(quote.get('03. high', 0)) if quote.get('03. high', '') != '' else 0.0,
                'low': float(quote.get('04. low', 0)) if quote.get('04. low', '') != '' else 0.0,
                'price': float(quote.get('05. price', 0)) if quote.get('05. price', '') != '' else 0.0,
                'volume': int(quote.get('06. volume', 0)) if quote.get('06. volume', '') != '' else 0,
                'latest_trading_day': quote.get('07. latest trading day'),
                'previous_close': float(quote.get('08. previous close', 0)) if quote.get('08. previous close', '') != '' else 0.0,
                'change': float(quote.get('09. change', 0)) if quote.get('09. change', '') != '' else 0.0,
                'change_percent': quote.get('10. change percent', '0%')
            }

            # ğŸ¯ ä¿å­˜åˆ°ä¼šè¯ç›®å½•æ ¹ç›®å½•ï¼ˆä¿®æ”¹ï¼šå»æ‰å­ç›®å½•ï¼‰
            if session_dir:
                file_path = session_dir / f"quote_{symbol}.json"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                logger.info(f"å®æ—¶è¡Œæƒ…å·²ä¿å­˜è‡³ä¼šè¯ç›®å½•ï¼š{file_path}")

            return result

        except Exception as e:
            logger.error(f"è·å–å®æ—¶è¡Œæƒ…å¤±è´¥: {e}")
            raise
    
    # ============ æœŸæƒæ•°æ®æ–¹æ³• ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(2), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_historical_options(symbol: str, date: str = None, session_dir: Path = None) -> List[Dict]:
        """è·å–å†å²æœŸæƒæ•°æ®"""
        try:
            params = {
                "function": "HISTORICAL_OPTIONS",
                "symbol": symbol,
                "apikey": AlphaVantageFetcher.get_api_key()
            }
            if date:
                params["date"] = date

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            # æ£€æŸ¥APIè¿”å›çš„é”™è¯¯ä¿¡æ¯
            if "Information" in data:
                error_msg = data["Information"]
                logger.warning(f"AlphaVantage APIé™åˆ¶: {error_msg}")
                raise ValueError(f"éœ€è¦AlphaVantageä»˜è´¹APIå¥—é¤æ‰èƒ½è®¿é—®æœŸæƒæ•°æ®: {error_msg}")
            
            if "Note" in data:
                logger.warning(f"APIé¢‘ç‡é™åˆ¶æç¤º: {data['Note']}")
            
            if not data.get("data"):
                if "Error Message" in data:
                    raise ValueError(f"AlphaVantage APIé”™è¯¯: {data['Error Message']}")
                else:
                    logger.warning(f"æœªæ‰¾åˆ°{symbol}åœ¨{date}çš„æœŸæƒæ•°æ®")
                    return []

            # è½¬æ¢æ•°æ®ç±»å‹
            for contract in data["data"]:
                for field in ["strike", "last", "mark", "bid", "ask", 
                            "implied_volatility", "delta", "gamma", 
                            "theta", "vega", "rho"]:
                    if contract.get(field):
                        contract[field] = float(contract[field])
                for field in ["bid_size", "ask_size", "volume", "open_interest"]:
                    if contract.get(field):
                        contract[field] = int(contract[field])

            # ğŸ¯ ä¿å­˜åˆ°ä¼šè¯ç›®å½•æ ¹ç›®å½•ï¼ˆä¿®æ”¹ï¼šå»æ‰å­ç›®å½•ï¼‰
            if session_dir:
                file_path = session_dir / f"options_{symbol}_{date if date else 'latest'}.parquet"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                pd.DataFrame(data["data"]).to_parquet(file_path)
                logger.info(f"æœŸæƒæ•°æ®å·²ä¿å­˜è‡³ä¼šè¯ç›®å½•ï¼š{file_path}")
            else:
                # åå¤‡
                temp_dir = Path("/tmp/alphavantage_data") / "options"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"options_{symbol}_{date if date else 'latest'}.parquet"
                pd.DataFrame(data["data"]).to_parquet(file_path)
                logger.info(f"æœŸæƒæ•°æ®å·²ä¿å­˜è‡³ä¸´æ—¶ç›®å½•ï¼š{file_path}")

            return data["data"]

        except Exception as e:
            logger.error(f"è·å–æœŸæƒæ•°æ®å¤±è´¥: {e}")
            return []
    
    # ============ è´¢æŠ¥æ•°æ®æ–¹æ³• ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_earnings_transcript(symbol: str, quarter: str, session_dir: Path = None) -> Dict:
        """è·å–è´¢æŠ¥ç”µè¯ä¼šè®®è®°å½•"""
        try:
            params = {
                "function": "EARNINGS_CALL_TRANSCRIPT",
                "symbol": symbol,
                "quarter": quarter,
                "apikey": AlphaVantageFetcher.get_api_key()
            }
            
            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            # ğŸ¯ ä¿å­˜åˆ°ä¼šè¯ç›®å½•æ ¹ç›®å½•ï¼ˆä¿®æ”¹ï¼šå»æ‰å­ç›®å½•ï¼‰
            if session_dir:
                file_path = session_dir / f"transcript_{symbol}_{quarter}.json"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False)
                logger.info(f"è´¢æŠ¥ä¼šè®®è®°å½•å·²ä¿å­˜è‡³ä¼šè¯ç›®å½•ï¼š{file_path}")
            else:
                # åå¤‡
                temp_dir = Path("/tmp/alphavantage_data") / "transcripts"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"transcript_{symbol}_{quarter}.json"
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False)
                logger.info(f"è´¢æŠ¥ä¼šè®®è®°å½•å·²ä¿å­˜è‡³ä¸´æ—¶ç›®å½•ï¼š{file_path}")

            return data
            
        except Exception as e:
            logger.error(f"è·å–è´¢æŠ¥ä¼šè®®è®°å½•å¤±è´¥: {e}")
            raise
    
    # ============ å†…éƒ¨äº¤æ˜“æ•°æ®æ–¹æ³• ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_insider_transactions(symbol: str, session_dir: Path = None) -> List[Dict]:
        """è·å–å…¬å¸å†…éƒ¨äººäº¤æ˜“æ•°æ®"""
        try:
            params = {
                "function": "INSIDER_TRANSACTIONS",
                "symbol": symbol,
                "apikey": AlphaVantageFetcher.get_api_key()
            }
            
            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            # è½¬æ¢æ•°æ®ç±»å‹
            transactions = []
            for item in data.get("data", []):
                transactions.append({
                    "transaction_date": item.get("transaction_date"),
                    "ticker": item.get("ticker"),
                    "executive": item.get("executive"),
                    "executive_title": item.get("executive_title"),
                    "security_type": item.get("security_type"),
                    "acquisition_or_disposal": item.get("acquisition_or_disposal"),
                    "trade_type": "ä¹°å…¥" if item.get("acquisition_or_disposal") == "A" else "å–å‡º",
                    "shares": float(item.get("shares", 0)) if item.get("shares") else 0,
                    "share_price": float(item.get("share_price", 0)) if item.get("share_price") else 0,
                    "total_value": float(item.get("shares", 0)) * float(item.get("share_price", 0)) if item.get("shares") and item.get("share_price") else 0
                })

            # ğŸ¯ ä¿å­˜åˆ°ä¼šè¯ç›®å½•æ ¹ç›®å½•ï¼ˆä¿®æ”¹ï¼šå»æ‰å­ç›®å½•ï¼‰
            if session_dir:
                file_path = session_dir / f"insider_{symbol}.json"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(transactions, f, ensure_ascii=False)
                logger.info(f"å†…éƒ¨äººäº¤æ˜“æ•°æ®å·²ä¿å­˜è‡³ä¼šè¯ç›®å½•ï¼š{file_path}")
            else:
                # åå¤‡
                temp_dir = Path("/tmp/alphavantage_data") / "insider"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"insider_{symbol}.json"
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(transactions, f, ensure_ascii=False)
                logger.info(f"å†…éƒ¨äººäº¤æ˜“æ•°æ®å·²ä¿å­˜è‡³ä¸´æ—¶ç›®å½•ï¼š{file_path}")

            return transactions
            
        except Exception as e:
            logger.error(f"è·å–å†…éƒ¨äººäº¤æ˜“æ•°æ®å¤±è´¥: {e}")
            raise
    
    # ============ ETFæ•°æ®æ–¹æ³• ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_etf_profile(symbol: str, session_dir: Path = None) -> Dict:
        """è·å–ETFè¯¦ç»†ä¿¡æ¯å’ŒæŒä»“æ•°æ®"""
        try:
            params = {
                "function": "ETF_PROFILE",
                "symbol": symbol,
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            # æ ‡å‡†åŒ–æ•°æ®ç»“æ„
            profile = {
                "symbol": data.get("symbol", symbol),
                "name": data.get("name"),
                "description": data.get("description"),
                "exchange": data.get("exchange"),
                "net_assets": float(data.get("net_assets", 0)),
                "expense_ratio": float(data.get("expense_ratio", 0)),
                "portfolio_turnover": float(data.get("portfolio_turnover", 0)),
                "dividend_yield": float(data.get("dividend_yield", 0)),
                "inception_date": data.get("inception_date"),
                "leveraged": data.get("leveraged", "").upper() == "YES",
                "sectors": [],
                "holdings": []
            }

            # å¤„ç†è¡Œä¸šé…ç½®æ•°æ®
            if isinstance(data.get("sectors"), list):
                for sector in data["sectors"]:
                    if isinstance(sector, dict):
                        profile["sectors"].append({
                            "sector": sector.get("sector"),
                            "weight": float(sector.get("weight", 0))
                        })

            # å¤„ç†æŒä»“æ•°æ®
            if isinstance(data.get("holdings"), list):
                for holding in data["holdings"]:
                    if isinstance(holding, dict):
                        profile["holdings"].append({
                            "symbol": holding.get("symbol"),
                            "name": holding.get("name"),
                            "weight": float(holding.get("weight", 0)),
                            "shares": int(holding.get("shares", 0)) 
                        })

            # ğŸ¯ ä¿å­˜åˆ°ä¼šè¯ç›®å½•æ ¹ç›®å½•ï¼ˆä¿®æ”¹ï¼šå»æ‰å­ç›®å½•ï¼‰
            if session_dir:
                file_path = session_dir / f"etf_{symbol}_profile.json"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(profile, f, ensure_ascii=False, indent=2)
                logger.info(f"ETFæ•°æ®å·²ä¿å­˜è‡³ä¼šè¯ç›®å½•ï¼š{file_path}")
            else:
                # åå¤‡
                temp_dir = Path("/tmp/alphavantage_data") / "etf"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"etf_{symbol}_profile.json"
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(profile, f, ensure_ascii=False, indent=2)
                logger.info(f"ETFæ•°æ®å·²ä¿å­˜è‡³ä¸´æ—¶ç›®å½•ï¼š{file_path}")
            
            return profile
            
        except Exception as e:
            logger.error(f"è·å–ETFæ•°æ®å¤±è´¥: {e}")
            raise
    
    # ============ å¤–æ±‡æ•°æ®æ–¹æ³• ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_forex_daily(
        from_symbol: str = "USD",
        to_symbol: str = "JPY",
        outputsize: str = "full",
        session_dir: Path = None
    ) -> pd.DataFrame:
        """è·å–å¤–æ±‡æ¯æ—¥æ•°æ®"""
        try:
            params = {
                "function": "FX_DAILY",
                "from_symbol": from_symbol,
                "to_symbol": to_symbol,
                "outputsize": outputsize,
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            time_series = data.get("Time Series FX (Daily)", {})
            if not time_series:
                raise ValueError(f"æœªè·å–åˆ°å¤–æ±‡æ•°æ®ï¼Œå“åº”: {data}")

            df = pd.DataFrame.from_dict(time_series, orient="index")
            df.index = pd.to_datetime(df.index)
            df = df.sort_index()

            df = df.rename(columns={
                "1. open": "open",
                "2. high": "high", 
                "3. low": "low",
                "4. close": "close"
            })

            df = df.astype({
                "open": float,
                "high": float,
                "low": float,
                "close": float
            })

            # ğŸ¯ ä¿å­˜åˆ°ä¼šè¯ç›®å½•æ ¹ç›®å½•ï¼ˆä¿®æ”¹ï¼šå»æ‰å­ç›®å½•ï¼‰
            if session_dir:
                file_path = session_dir / f"forex_{from_symbol}_{to_symbol}.parquet"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                df.to_parquet(file_path)
                logger.info(f"å¤–æ±‡æ•°æ®å·²ä¿å­˜è‡³ä¼šè¯ç›®å½•: {file_path}")
            else:
                # åå¤‡
                temp_dir = Path("/tmp/alphavantage_data") / "forex"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"forex_{from_symbol}_{to_symbol}_daily.parquet"
                df.to_parquet(file_path)
                logger.info(f"å¤–æ±‡æ•°æ®å·²ä¿å­˜è‡³ä¸´æ—¶ç›®å½•: {file_path}")

            return df

        except Exception as e:
            logger.error(f"è·å–{from_symbol}/{to_symbol}å¤–æ±‡æ•°æ®å¤±è´¥: {e}")
            raise
    
    # ============ æ•°å­—è´§å¸æ•°æ®æ–¹æ³• ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_digital_currency_daily(
        symbol: str,
        market: str,
        session_dir: Path = None
    ) -> Dict[str, pd.DataFrame]:
        """è·å–æ•°å­—è´§å¸æ¯æ—¥æ•°æ®"""
        try:
            params = {
                "function": "DIGITAL_CURRENCY_DAILY",
                "symbol": symbol,
                "market": market,
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            time_series = data.get("Time Series (Digital Currency Daily)", {})
            if not time_series:
                raise ValueError(f"æœªè·å–åˆ°æ•°å­—è´§å¸æ•°æ®ï¼Œå“åº”: {data}")

            # è½¬æ¢ä¸ºDataFrameå¹¶å¤„ç†æ•°æ®
            df = pd.DataFrame.from_dict(time_series, orient="index")
            df.index = pd.to_datetime(df.index)
            df = df.sort_index()

            # å¤„ç†å¸‚åœºè´§å¸æ•°æ®
            if market == "USD":
                # USDå¸‚åœºä½¿ç”¨åŸºæœ¬åˆ—å
                market_df = df[[
                    "1. open",
                    "2. high",
                    "3. low",
                    "4. close",
                    "5. volume"
                ]].rename(columns={
                    "1. open": "open",
                    "2. high": "high",
                    "3. low": "low",
                    "4. close": "close",
                    "5. volume": "volume"
                })
                usd_df = market_df[["open", "high", "low", "close"]].copy()
            else:
                def get_column(df, prefix, currency):
                    """è¾…åŠ©å‡½æ•°è·å–æŒ‡å®šå‰ç¼€å’Œå¤§å°çš„åˆ—"""
                    for col in df.columns:
                        if f"{prefix}. " in col and f"({currency})" in col and not "(convert)" in col:
                            return col
                    raise ValueError(f"æ‰¾ä¸åˆ°{prefix} {currency}åˆ—")

                # è·å–å¸‚åœºè´§å¸è®¡ä»·æ•°æ®åˆ—
                market_open = get_column(df, "1a", market)
                market_high = get_column(df, "2a", market)
                market_low = get_column(df, "3a", market)
                market_close = get_column(df, "4a", market)
                volume_col = "5. volume"

                market_df = df[[
                    market_open,
                    market_high,
                    market_low,
                    market_close,
                    volume_col
                ]].rename(columns={
                    market_open: "open",
                    market_high: "high", 
                    market_low: "low",
                    market_close: "close",
                    volume_col: "volume"
                })

                # è·å–ç¾å…ƒè®¡ä»·æ•°æ®åˆ—
                usd_open = get_column(df, "1b", "USD")
                usd_high = get_column(df, "2b", "USD")
                usd_low = get_column(df, "3b", "USD")
                usd_close = get_column(df, "4b", "USD")

                usd_df = df[[
                    usd_open,
                    usd_high,
                    usd_low,
                    usd_close
                ]].rename(columns={
                    usd_open: "open",
                    usd_high: "high",
                    usd_low: "low",
                    usd_close: "close"
                })

            # è½¬æ¢æ•°æ®ç±»å‹
            market_df = market_df.astype({
                "open": float, "high": float, "low": float, 
                "close": float, "volume": float
            })
            usd_df = usd_df.astype({
                "open": float, "high": float, "low": float, "close": float
            })

            # ğŸ¯ ä¿å­˜åˆ°ä¼šè¯ç›®å½•æ ¹ç›®å½•ï¼ˆä¿®æ”¹ï¼šå»æ‰å­ç›®å½•ï¼‰
            if session_dir:
                # ç›´æ¥ä¿å­˜åˆ°ä¼šè¯æ ¹ç›®å½•ï¼Œä¸å†åˆ›å»º crypto å­ç›®å½•
                if market == "USD":
                    file_path = session_dir / f"crypto_{symbol}_USD.parquet"
                    market_df.to_parquet(file_path)
                    logger.info(f"USDå¸‚åœºæ•°æ®å·²ä¿å­˜è‡³ä¼šè¯ç›®å½•: {file_path}")
                else:
                    market_file = session_dir / f"crypto_{symbol}_{market}.parquet"
                    usd_file = session_dir / f"crypto_{symbol}_USD.parquet"
                    market_df.to_parquet(market_file)
                    usd_df.to_parquet(usd_file)
                    logger.info(f"æ•°å­—è´§å¸{symbol}æ•°æ®å·²ä¿å­˜è‡³ä¼šè¯ç›®å½•: {session_dir}")
            else:
                # åå¤‡
                temp_dir = Path("/tmp/alphavantage_data") / "digital_currency"
                temp_dir.mkdir(parents=True, exist_ok=True)
                
                if market == "USD":
                    file_path = temp_dir / f"crypto_{symbol}_USD.parquet"
                    market_df.to_parquet(file_path)
                    logger.info(f"USDå¸‚åœºæ•°æ®å·²ä¿å­˜è‡³ä¸´æ—¶ç›®å½•: {file_path}")
                else:
                    market_file = temp_dir / f"crypto_{symbol}_{market}.parquet"
                    usd_file = temp_dir / f"crypto_{symbol}_USD.parquet"
                    market_df.to_parquet(market_file)
                    usd_df.to_parquet(usd_file)
                    logger.info(f"æ•°å­—è´§å¸{symbol}æ•°æ®å·²ä¿å­˜è‡³ä¸´æ—¶ç›®å½•: {temp_dir}")

            return {
                "market": market_df,
                "usd": usd_df
            }

        except Exception as e:
            logger.error(f"è·å–{symbol}/{market}æ•°å­—è´§å¸æ•°æ®å¤±è´¥: {e}")
            raise
    
    # ============ å¤§å®—å•†å“æ•°æ®æ–¹æ³• ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_wti(
        interval: str = "monthly",
        session_dir: Path = None
    ) -> pd.DataFrame:
        """è·å–WTIåŸæ²¹ä»·æ ¼æ•°æ®"""
        try:
            params = {
                "function": "WTI",
                "interval": interval,
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            if not data.get("data"):
                raise ValueError("No WTI data found in response")

            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(data["data"])
            df["date"] = pd.to_datetime(df["date"])
            df["price"] = pd.to_numeric(df["value"], errors='coerce')
            df = df.dropna(subset=['price'])
            df["price"] = df["price"].astype(float)
            df = df.drop(columns=["value"])
            df = df.set_index("date").sort_index()

            # ğŸ¯ ä¿å­˜åˆ°ä¼šè¯ç›®å½•æ ¹ç›®å½•ï¼ˆä¿®æ”¹ï¼šå»æ‰å­ç›®å½•ï¼‰
            if session_dir:
                file_path = session_dir / f"commodity_WTI_{interval}.parquet"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                df.to_parquet(file_path)
                logger.info(f"WTIåŸæ²¹æ•°æ®å·²ä¿å­˜è‡³ä¼šè¯ç›®å½•: {file_path}")
            else:
                # åå¤‡
                temp_dir = Path("/tmp/alphavantage_data") / "commodities"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"commodity_WTI_{interval}.parquet"
                df.to_parquet(file_path)
                logger.info(f"WTIåŸæ²¹æ•°æ®å·²ä¿å­˜è‡³ä¸´æ—¶ç›®å½•: {file_path}")

            return df

        except Exception as e:
            logger.error(f"è·å–WTIåŸæ²¹æ•°æ®å¤±è´¥: {e}")
            raise
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_brent(
        interval: str = "monthly",
        session_dir: Path = None
    ) -> pd.DataFrame:
        """è·å–BrentåŸæ²¹ä»·æ ¼æ•°æ®"""
        try:
            params = {
                "function": "BRENT",
                "interval": interval,
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            if not data.get("data"):
                raise ValueError("No Brent data found in response")

            # è½¬æ¢ä¸ºDataFrameå¹¶ä¸¥æ ¼å¤„ç†æ•°æ®
            df = pd.DataFrame(data["data"])
            df["date"] = pd.to_datetime(df["date"])
            df["price"] = pd.to_numeric(df["value"], errors='coerce')
            invalid_count = df["price"].isna().sum()
            if invalid_count > 0:
                logger.warning(f"è¿‡æ»¤æ‰{invalid_count}æ¡æ— æ•ˆåŸæ²¹æ•°æ®")
                df = df.dropna(subset=['price'])
            
            df["price"] = df["price"].astype(float)
            df = df.drop(columns=["value"])
            df = df.set_index("date").sort_index()
            
            if len(df) == 0:
                raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„åŸæ²¹æ•°æ®å¯ç”¨")

            # ğŸ¯ ä¿å­˜åˆ°ä¼šè¯ç›®å½•æ ¹ç›®å½•ï¼ˆä¿®æ”¹ï¼šå»æ‰å­ç›®å½•ï¼‰
            if session_dir:
                file_path = session_dir / f"commodity_BRENT_{interval}.parquet"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                df.to_parquet(file_path)
                logger.info(f"BrentåŸæ²¹æ•°æ®å·²ä¿å­˜è‡³ä¼šè¯ç›®å½•: {file_path}")
            else:
                # åå¤‡
                temp_dir = Path("/tmp/alphavantage_data") / "commodities"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"commodity_BRENT_{interval}.parquet"
                df.to_parquet(file_path)
                logger.info(f"BrentåŸæ²¹æ•°æ®å·²ä¿å­˜è‡³ä¸´æ—¶ç›®å½•: {file_path}")

            return df

        except Exception as e:
            logger.error(f"è·å–BrentåŸæ²¹æ•°æ®å¤±è´¥: {e}")
            raise
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_copper(
        interval: str = "monthly",
        session_dir: Path = None
    ) -> pd.DataFrame:
        """è·å–å…¨çƒé“œä»·æ•°æ®"""
        try:
            params = {
                "function": "COPPER",
                "interval": interval,
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            if not data.get("data"):
                raise ValueError("No copper price data found in response")

            # è½¬æ¢ä¸ºDataFrameå¹¶ä¸¥æ ¼å¤„ç†æ•°æ®
            df = pd.DataFrame(data["data"])
            df["date"] = pd.to_datetime(df["date"])
            df["price"] = pd.to_numeric(df["value"], errors='coerce')
            invalid_count = df["price"].isna().sum()
            if invalid_count > 0:
                logger.warning(f"è¿‡æ»¤æ‰{invalid_count}æ¡æ— æ•ˆé“œä»·æ•°æ®")
                df = df.dropna(subset=['price'])
            
            df["price"] = df["price"].astype(float)
            df = df.drop(columns=["value"])
            df = df.set_index("date").sort_index()
            
            if len(df) == 0:
                raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„é“œä»·æ•°æ®å¯ç”¨")

            # ğŸ¯ ä¿å­˜åˆ°ä¼šè¯ç›®å½•æ ¹ç›®å½•ï¼ˆä¿®æ”¹ï¼šå»æ‰å­ç›®å½•ï¼‰
            if session_dir:
                file_path = session_dir / f"commodity_COPPER_{interval}.parquet"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                df.to_parquet(file_path)
                logger.info(f"é“œä»·æ•°æ®å·²ä¿å­˜è‡³ä¼šè¯ç›®å½•: {file_path}")
            else:
                # åå¤‡
                temp_dir = Path("/tmp/alphavantage_data") / "commodities"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"commodity_COPPER_{interval}.parquet"
                df.to_parquet(file_path)
                logger.info(f"é“œä»·æ•°æ®å·²ä¿å­˜è‡³ä¸´æ—¶ç›®å½•: {file_path}")

            return df

        except Exception as e:
            logger.error(f"è·å–é“œä»·æ•°æ®å¤±è´¥: {e}")
            raise
    
    # ============ å›½å€ºæ”¶ç›Šç‡æ•°æ®æ–¹æ³• ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10)) 
    def fetch_treasury_yield(
        interval: str = "monthly",
        maturity: str = "10year",
        session_dir: Path = None
    ) -> pd.DataFrame:
        """è·å–ç¾å›½å›½å€ºæ”¶ç›Šç‡æ•°æ®"""
        try:
            params = {
                "function": "TREASURY_YIELD",
                "interval": interval,
                "maturity": maturity,
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            if not data.get("data"):
                raise ValueError("æœªè·å–åˆ°å›½å€ºæ”¶ç›Šç‡æ•°æ®")
                
            # è½¬æ¢ä¸ºDataFrameå¹¶å¤„ç†æ•°æ®
            df = pd.DataFrame(data["data"])
            df["date"] = pd.to_datetime(df["date"])
            df["yield"] = pd.to_numeric(df["value"], errors="coerce")
            df = df.dropna(subset=["yield"])
            
            # ğŸ¯ ä¿å­˜åˆ°ä¼šè¯ç›®å½•æ ¹ç›®å½•ï¼ˆä¿®æ”¹ï¼šå»æ‰å­ç›®å½•ï¼‰
            if session_dir:
                file_path = session_dir / f"treasury_{maturity}_{interval}.parquet"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                df.to_parquet(file_path)
                logger.info(f"å›½å€ºæ”¶ç›Šç‡æ•°æ®å·²ä¿å­˜è‡³ä¼šè¯ç›®å½•: {file_path}")
            else:
                # åå¤‡
                temp_dir = Path("/tmp/alphavantage_data") / "treasury"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"treasury_{maturity}_{interval}.parquet"
                df.to_parquet(file_path)
                logger.info(f"å›½å€ºæ”¶ç›Šç‡æ•°æ®å·²ä¿å­˜è‡³ä¸´æ—¶ç›®å½•: {file_path}")
            
            return df[["date", "yield"]]
            
        except Exception as e:
            logger.error(f"è·å–å›½å€ºæ”¶ç›Šç‡æ•°æ®å¤±è´¥: {e}")
            raise
    
    # ============ æ–°é—»æƒ…ç»ªæ•°æ®æ–¹æ³• ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_news_sentiment(
        tickers: str = None,
        topics: str = None,
        time_from: str = None,
        time_to: str = None,
        sort: str = "LATEST",
        limit: int = 50,
        session_dir: Path = None
    ) -> Dict:
        """è·å–å¸‚åœºæ–°é—»å’Œæƒ…ç»ªæ•°æ®"""
        try:
            params = {
                "function": "NEWS_SENTIMENT",
                "apikey": AlphaVantageFetcher.get_api_key(),
                "sort": sort,
                "limit": limit
            }
            if tickers:
                params["tickers"] = tickers
            if topics:
                params["topics"] = topics
            if time_from:
                params["time_from"] = time_from
            if time_to:
                params["time_to"] = time_to

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            filename_parts = []
            if tickers:
                filename_parts.append(tickers.replace(',','_'))
            if topics:
                filename_parts.append(topics.replace(',','_'))
            if time_from:
                filename_parts.append(f"from_{time_from}")
            if time_to:
                filename_parts.append(f"to_{time_to}")
            if not filename_parts:
                filename_parts.append("latest")
            
            safe_filename = '_'.join(filename_parts).replace(':', '_').replace('/', '_').replace(' ', '_')
            filename = f"news_{safe_filename}.json"
            
            # ğŸ¯ ä¿å­˜åˆ°ä¼šè¯ç›®å½•æ ¹ç›®å½•ï¼ˆä¿®æ”¹ï¼šå»æ‰å­ç›®å½•ï¼‰
            if session_dir:
                file_path = session_dir / filename
                file_path.parent.mkdir(parents=True, exist_ok=True)
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False)
                logger.info(f"æ–°é—»æ•°æ®å·²ä¿å­˜è‡³ä¼šè¯ç›®å½•ï¼š{file_path}")
            else:
                # åå¤‡
                temp_dir = Path("/tmp/alphavantage_data") / "news"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / filename
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False)
                logger.info(f"æ–°é—»æ•°æ®å·²ä¿å­˜è‡³ä¸´æ—¶ç›®å½•ï¼š{file_path}")

            return data

        except Exception as e:
            logger.error(f"è·å–æ–°é—»æ•°æ®å¤±è´¥: {e}")
            raise

# ==================== å·¥å…·ç±» ====================
class AlphaVantageTool:
    """AlphaVantageé‡‘èæ•°æ®è·å–å·¥å…· - æœ€ç»ˆä¼˜åŒ–ç‰ˆ"""
    
    name = "alphavantage"
    description = (
        "ä»AlphaVantageè·å–é‡‘èæ•°æ®çš„å®Œæ•´å·¥å…·ã€‚æ”¯æŒè‚¡ç¥¨ã€æœŸæƒã€è´¢æŠ¥ã€å†…éƒ¨äº¤æ˜“ã€ETFã€å¤–æ±‡ã€"
        "æ•°å­—è´§å¸ã€å¤§å®—å•†å“ã€å›½å€ºæ”¶ç›Šç‡ã€æ–°é—»æƒ…ç»ªç­‰13ç§æ•°æ®ç±»å‹ã€‚æ•°æ®ä¼šä¿å­˜åˆ°ä¼šè¯å·¥ä½œåŒºã€‚"
    )
    input_schema = AlphaVantageInput
    
    def __init__(self):
        # ç¡®ä¿å·¥ä½œåŒºæ ¹ç›®å½•å­˜åœ¨
        SESSION_WORKSPACE_ROOT.mkdir(exist_ok=True, parents=True)
        logger.info(f"AlphaVantageå·¥å…·åˆå§‹åŒ–ï¼Œå·¥ä½œåŒºç›®å½•: {SESSION_WORKSPACE_ROOT}")
        
        # éªŒè¯API Key
        self._validate_api_key()
        
        # æ¨¡å¼åˆ°æ–¹æ³•æ˜ å°„
        self._mode_to_method = {
            AlphaVantageMode.WEEKLY_ADJUSTED: {
                "method": AlphaVantageFetcher.fetch_weekly_adjusted,
                "params_model": WeeklyAdjustedParams,
                "timeout": 30
            },
            AlphaVantageMode.GLOBAL_QUOTE: {
                "method": AlphaVantageFetcher.fetch_global_quote,
                "params_model": GlobalQuoteParams,
                "timeout": 30
            },
            AlphaVantageMode.HISTORICAL_OPTIONS: {
                "method": AlphaVantageFetcher.fetch_historical_options,
                "params_model": HistoricalOptionsParams,
                "timeout": 45
            },
            AlphaVantageMode.EARNINGS_TRANSCRIPT: {
                "method": AlphaVantageFetcher.fetch_earnings_transcript,
                "params_model": EarningsTranscriptParams,
                "timeout": 45
            },
            AlphaVantageMode.INSIDER_TRANSACTIONS: {
                "method": AlphaVantageFetcher.fetch_insider_transactions,
                "params_model": InsiderTransactionsParams,
                "timeout": 30
            },
            AlphaVantageMode.ETF_PROFILE: {
                "method": AlphaVantageFetcher.fetch_etf_profile,
                "params_model": ETFProfileParams,
                "timeout": 30
            },
            AlphaVantageMode.FOREX_DAILY: {
                "method": AlphaVantageFetcher.fetch_forex_daily,
                "params_model": ForexDailyParams,
                "timeout": 30
            },
            AlphaVantageMode.DIGITAL_CURRENCY_DAILY: {
                "method": AlphaVantageFetcher.fetch_digital_currency_daily,
                "params_model": DigitalCurrencyDailyParams,
                "timeout": 30
            },
            AlphaVantageMode.WTI: {
                "method": AlphaVantageFetcher.fetch_wti,
                "params_model": CommodityParams,
                "timeout": 30
            },
            AlphaVantageMode.BRENT: {
                "method": AlphaVantageFetcher.fetch_brent,
                "params_model": CommodityParams,
                "timeout": 30
            },
            AlphaVantageMode.COPPER: {
                "method": AlphaVantageFetcher.fetch_copper,
                "params_model": CommodityParams,
                "timeout": 30
            },
            AlphaVantageMode.TREASURY_YIELD: {
                "method": AlphaVantageFetcher.fetch_treasury_yield,
                "params_model": TreasuryYieldParams,
                "timeout": 30
            },
            AlphaVantageMode.NEWS_SENTIMENT: {
                "method": AlphaVantageFetcher.fetch_news_sentiment,
                "params_model": NewsSentimentParams,
                "timeout": 45
            }
        }
    
    def _validate_api_key(self):
        """éªŒè¯API Keyæ˜¯å¦é…ç½®"""
        try:
            api_key = AlphaVantageFetcher.get_api_key()
            if api_key and api_key != "U5KM36DHDXR95Q7Q":
                logger.info("âœ… AlphaVantage API Key å·²æ­£ç¡®é…ç½®")
            else:
                logger.warning("âš ï¸ AlphaVantage API Key æœªé…ç½®æˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶")
        except Exception as e:
            logger.error(f"éªŒè¯API Keyæ—¶å‡ºé”™: {e}")
    
    def _ensure_session_workspace(self, session_id: str = None) -> Path:
        """ç¡®ä¿ä¼šè¯å·¥ä½œåŒºå­˜åœ¨"""
        if not session_id:
            # ä¸´æ—¶ç›®å½•
            temp_dir = SESSION_WORKSPACE_ROOT / "temp" / str(int(datetime.now().timestamp()))
            temp_dir.mkdir(parents=True, exist_ok=True)
            return temp_dir
        
        session_dir = SESSION_WORKSPACE_ROOT / session_id
        session_dir.mkdir(parents=True, exist_ok=True)
        
        # ğŸ¯ æ³¨æ„ï¼šä¸å†åˆ›å»ºå­ç›®å½•ç»“æ„ï¼Œå› ä¸ºæ–‡ä»¶éƒ½ç›´æ¥ä¿å­˜åœ¨æ ¹ç›®å½•
        # ä¿ç•™åŸæœ‰çš„å­ç›®å½•åˆ›å»ºä»£ç ä½†ä¸ä½¿ç”¨ï¼Œä¸ºäº†å‘åå…¼å®¹
        subdirs = [
            "stock", "options", "transcripts", "insider", "etf", 
            "forex", "crypto", "commodities", "treasury", "news"
        ]
        
        for subdir in subdirs:
            (session_dir / subdir).mkdir(exist_ok=True)
        
        return session_dir
    
    async def _execute_with_timeout(self, func, timeout: int = 60):
        """å¸¦è¶…æ—¶çš„å‡½æ•°æ‰§è¡Œ"""
        try:
            # å°†åŒæ­¥å‡½æ•°åŒ…è£…ä¸ºå¼‚æ­¥
            return await asyncio.wait_for(
                asyncio.get_event_loop().run_in_executor(None, func),
                timeout=timeout
            )
        except asyncio.TimeoutError:
            logger.error(f"â° æ“ä½œè¶…æ—¶ ({timeout}ç§’)")
            raise
    
    async def execute(self, parameters: AlphaVantageInput, session_id: str = None) -> dict:
        """æ‰§è¡ŒAlphaVantageæ•°æ®è·å– - ä¸»å…¥å£"""
        try:
            mode = parameters.mode
            params = parameters.parameters
            
            logger.info(f"ğŸš€ æ‰§è¡Œ AlphaVantage æ¨¡å¼: {mode.value}")
            
            # æ£€æŸ¥æ¨¡å¼æ˜¯å¦æ”¯æŒ
            if mode not in self._mode_to_method:
                return {
                    "success": False,
                    "error": f"ä¸æ”¯æŒçš„AlphaVantageæ¨¡å¼: {mode.value}",
                    "available_modes": [m.value for m in AlphaVantageMode]
                }
            
            # ç¡®ä¿ä¼šè¯å·¥ä½œåŒº
            session_dir = self._ensure_session_workspace(session_id)
            
            # è·å–æ¨¡å¼é…ç½®
            mode_config = self._mode_to_method[mode]
            method = mode_config["method"]
            params_model = mode_config["params_model"]
            timeout = mode_config["timeout"]
            
            # éªŒè¯å‚æ•°
            try:
                validated_params = params_model(**params)
            except Exception as e:
                logger.error(f"âŒ å‚æ•°éªŒè¯å¤±è´¥: {e}")
                return {
                    "success": False,
                    "error": f"å‚æ•°éªŒè¯å¤±è´¥: {str(e)}",
                    "mode": mode.value
                }
            
            # ğŸ¯ æ‰§è¡ŒAPIè°ƒç”¨
            try:
                result = await self._execute_with_timeout(
                    lambda: method(**validated_params.dict(), session_dir=session_dir),
                    timeout=timeout
                )
            except Exception as e:
                logger.error(f"âŒ APIè°ƒç”¨å¤±è´¥: {e}")
                return {
                    "success": False,
                    "error": f"APIè°ƒç”¨å¤±è´¥: {str(e)}",
                    "mode": mode.value
                }
            
            # æ„å»ºå…ƒæ•°æ®
            metadata = {
                "mode": mode.value,
                "parameters": params,
                "session_id": session_id,
                "timestamp": datetime.now().isoformat(),
                "session_dir": str(session_dir),
                "saved_files": self._get_saved_file_paths(session_dir, mode, params)
            }
            
            # å¤„ç†ç»“æœ
            processed_result = self._process_result(result, mode)
            
            # æ„å»ºå“åº”
            response = {
                "success": True,
                "data": processed_result,
                "metadata": metadata
            }
            
            # æ·»åŠ ç¤ºä¾‹ä»£ç ï¼ˆæ›´æ–°è·¯å¾„å¼•ç”¨ï¼‰
            if session_id:
                example_code = self._generate_example_code(mode, params, session_dir)
                response["metadata"]["example_code"] = example_code
                response["metadata"]["instructions"] = (
                    f"æ•°æ®å·²ä¿å­˜åˆ°ä¼šè¯ç›®å½• {session_dir}ï¼Œ"
                    f"ä»£ç è§£é‡Šå™¨å¯ä»¥é€šè¿‡ '/srv/sandbox_workspaces/{session_id}/' è®¿é—®è¿™äº›æ–‡ä»¶ã€‚"
                )
            
            logger.info(f"âœ… AlphaVantageå·¥å…·æ‰§è¡ŒæˆåŠŸ: {mode.value}")
            return response
            
        except Exception as e:
            logger.error(f"âŒ AlphaVantageå·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
            return {
                "success": False,
                "error": f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}",
                "mode": parameters.mode.value if hasattr(parameters, 'mode') else "unknown"
            }
    
    def _get_saved_file_paths(self, session_dir: Path, mode: AlphaVantageMode, params: dict) -> List[str]:
        """è·å–å·²ä¿å­˜çš„æ–‡ä»¶è·¯å¾„"""
        try:
            if mode == AlphaVantageMode.WEEKLY_ADJUSTED:
                symbol = params.get("symbol")
                if symbol:
                    # ğŸ¯ æ›´æ–°æ–‡ä»¶è·¯å¾„ä¸ºæ ¹ç›®å½•
                    file_path = session_dir / f"stock_{symbol}.parquet"
                    return [str(file_path)] if file_path.exists() else []
            
            elif mode == AlphaVantageMode.GLOBAL_QUOTE:
                symbol = params.get("symbol")
                if symbol:
                    # ğŸ¯ æ›´æ–°æ–‡ä»¶è·¯å¾„ä¸ºæ ¹ç›®å½•
                    file_path = session_dir / f"quote_{symbol}.json"
                    return [str(file_path)] if file_path.exists() else []
            
            elif mode == AlphaVantageMode.FOREX_DAILY:
                from_sym = params.get("from_symbol", "USD")
                to_sym = params.get("to_symbol", "JPY")
                # ğŸ¯ æ›´æ–°æ–‡ä»¶è·¯å¾„ä¸ºæ ¹ç›®å½•
                file_path = session_dir / f"forex_{from_sym}_{to_sym}.parquet"
                return [str(file_path)] if file_path.exists() else []
            
            elif mode == AlphaVantageMode.NEWS_SENTIMENT:
                tickers = params.get("tickers", "general")
                safe_tickers = tickers.replace(',', '_').replace(' ', '_') if tickers else "general"
                # ğŸ¯ æ›´æ–°æ–‡ä»¶è·¯å¾„ä¸ºæ ¹ç›®å½•
                file_path = session_dir / f"news_{safe_tickers}.json"
                return [str(file_path)] if file_path.exists() else []
            
            # å…¶ä»–æ¨¡å¼å¯ä»¥ç±»ä¼¼æ·»åŠ ...
            
            return []
        except Exception as e:
            logger.warning(f"è·å–ä¿å­˜æ–‡ä»¶è·¯å¾„å¤±è´¥: {e}")
            return []
    
    def _process_result(self, result, mode: AlphaVantageMode):
        """å¤„ç†è¿”å›ç»“æœï¼Œç¡®ä¿å¯åºåˆ—åŒ–"""
        if result is None:
            return {"message": "æœªè·å–åˆ°æ•°æ®"}
        
        # ç‰¹æ®Šå¤„ç†æ•°å­—è´§å¸æ•°æ®
        if mode == AlphaVantageMode.DIGITAL_CURRENCY_DAILY:
            if isinstance(result, dict) and "market" in result and "usd" in result:
                processed_result = {}
                
                # å¤„ç† market DataFrame
                if hasattr(result["market"], 'to_dict'):
                    market_df = result["market"]
                    processed_result["market"] = self._process_dataframe(market_df)
                
                # å¤„ç† usd DataFrame
                if hasattr(result["usd"], 'to_dict'):
                    usd_df = result["usd"]
                    processed_result["usd"] = self._process_dataframe(usd_df)
                
                return processed_result
        
        # å¤„ç† DataFrame
        if hasattr(result, 'to_dict'):
            return self._process_dataframe(result)
        
        # å¤„ç†å­—å…¸æˆ–åˆ—è¡¨
        if isinstance(result, (dict, list)):
            if isinstance(result, list) and len(result) > 100:
                return {
                    "total_records": len(result),
                    "sample_data": result[:10],
                    "message": f"æ•°æ®è¿‡å¤šï¼Œæ˜¾ç¤ºå‰10æ¡ï¼Œå…±{len(result)}æ¡"
                }
            return result
        
        return {"result": str(result)}
    
    def _process_dataframe(self, df):
        """å¤„ç†DataFrameè½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼"""
        try:
            if hasattr(df, 'index'):
                df_processed = df.reset_index()
                if 'index' in df_processed.columns:
                    df_processed = df_processed.rename(columns={'index': 'date'})
                
                if len(df_processed) > 100:
                    return {
                        "total_records": len(df_processed),
                        "date_range": {
                            "start": str(df_processed['date'].min()) if 'date' in df_processed.columns else None,
                            "end": str(df_processed['date'].max()) if 'date' in df_processed.columns else None
                        },
                        "sample_data": df_processed.head(10).to_dict(orient='records'),
                        "message": f"æ•°æ®è¿‡å¤šï¼Œæ˜¾ç¤ºå‰10æ¡ï¼Œå…±{len(df_processed)}æ¡"
                    }
                else:
                    return df_processed.to_dict(orient='records')
            else:
                return df.to_dict(orient='records')
        except Exception as e:
            logger.warning(f"DataFrameè½¬æ¢å¤±è´¥: {e}")
            return {"raw_result": str(df)}
    
    def _generate_example_code(self, mode: AlphaVantageMode, params: dict, session_dir: Path) -> str:
        """ç”ŸæˆPythonä»£ç ç¤ºä¾‹"""
        if mode == AlphaVantageMode.WEEKLY_ADJUSTED:
            symbol = params.get("symbol", "UNKNOWN")
            return f'''# è¯»å– {symbol} è‚¡ç¥¨æ•°æ®
import pandas as pd
from pathlib import Path

# ä¼šè¯æ•°æ®è·¯å¾„ï¼ˆæ›´æ–°ä¸ºæ ¹ç›®å½•æ–‡ä»¶ï¼‰
data_path = Path('/srv/sandbox_workspaces/{session_dir.name}/stock_{symbol}.parquet')
if data_path.exists():
    df = pd.read_parquet(data_path)
    print(f"{{'{symbol}'}} è‚¡ç¥¨æ•°æ®:")
    print(f"æ•°æ®å½¢çŠ¶: {{df.shape}}")
    print(f"æ—¥æœŸèŒƒå›´: {{df.index.min()}} åˆ° {{df.index.max()}}")
    print("\\nå‰5è¡Œæ•°æ®:")
    print(df.head())
    
    # å¯è§†åŒ–
    import matplotlib.pyplot as plt
    plt.figure(figsize=(12, 6))
    plt.plot(df.index, df['close'], label='æ”¶ç›˜ä»·', linewidth=2)
    plt.title(f'{symbol} è‚¡ä»·èµ°åŠ¿')
    plt.xlabel('æ—¥æœŸ')
    plt.ylabel('ä»·æ ¼ (USD)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()'''
        
        elif mode == AlphaVantageMode.FOREX_DAILY:
            from_sym = params.get("from_symbol", "USD")
            to_sym = params.get("to_symbol", "JPY")
            return f'''# è¯»å– {from_sym}/{to_sym} å¤–æ±‡æ•°æ®
import pandas as pd
from pathlib import Path

# ä¼šè¯æ•°æ®è·¯å¾„ï¼ˆæ›´æ–°ä¸ºæ ¹ç›®å½•æ–‡ä»¶ï¼‰
data_path = Path('/srv/sandbox_workspaces/{session_dir.name}/forex_{from_sym}_{to_sym}.parquet')
if data_path.exists():
    df = pd.read_parquet(data_path)
    print(f"{{'{from_sym}/{to_sym}'}} å¤–æ±‡æ•°æ®:")
    print(f"æ•°æ®å½¢çŠ¶: {{df.shape}}")
    print("\\næœ€è¿‘10å¤©æ•°æ®:")
    print(df.tail(10))
    
    # è®¡ç®—æ”¶ç›Šç‡
    df['returns'] = df['close'].pct_change()
    print("\\næ”¶ç›Šç‡ç»Ÿè®¡:")
    print(df['returns'].describe())'''
        
        else:
            return f'''# è®¿é—®ä¼šè¯ç›®å½•ä¸­çš„æ‰€æœ‰æ•°æ®
import pandas as pd
import json
from pathlib import Path

# ä¼šè¯ç›®å½•è·¯å¾„
session_path = Path('/srv/sandbox_workspaces/{session_dir.name}')
print("ä¼šè¯ç›®å½•:", session_path)

# åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ–‡ä»¶
print("\\nå¯ç”¨æ–‡ä»¶:")
for file_path in session_path.iterdir():
    if file_path.is_file():
        size_kb = file_path.stat().st_size / 1024
        print(f"  - {{file_path.name}} ({{size_kb:.1f}} KB)")'''

# ==================== è¾…åŠ©å‡½æ•° ====================
def get_available_modes() -> List[str]:
    """è·å–æ‰€æœ‰å¯ç”¨çš„AlphaVantageæ¨¡å¼"""
    return [mode.value for mode in AlphaVantageMode]

def get_mode_description(mode_name: str) -> str:
    """è·å–æ¨¡å¼æè¿°"""
    descriptions = {
        "weekly_adjusted": "è·å–è‚¡ç¥¨å‘¨è°ƒæ•´æ•°æ®ï¼ˆå¼€ç›˜ä»·ã€æœ€é«˜ä»·ã€æœ€ä½ä»·ã€æ”¶ç›˜ä»·ã€è°ƒæ•´åæ”¶ç›˜ä»·ã€æˆäº¤é‡ã€è‚¡æ¯ï¼‰",
        "global_quote": "è·å–å®æ—¶è¡Œæƒ…æ•°æ®ï¼ˆå½“å‰ä»·æ ¼ã€æ¶¨è·Œå¹…ã€æˆäº¤é‡ç­‰ï¼‰",
        "historical_options": "è·å–å†å²æœŸæƒæ•°æ®ï¼ˆéœ€è¦ä»˜è´¹APIå¥—é¤ï¼‰",
        "earnings_transcript": "è·å–è´¢æŠ¥ç”µè¯ä¼šè®®è®°å½•",
        "insider_transactions": "è·å–å…¬å¸å†…éƒ¨äººäº¤æ˜“æ•°æ®",
        "etf_profile": "è·å–ETFè¯¦ç»†ä¿¡æ¯å’ŒæŒä»“æ•°æ®",
        "forex_daily": "è·å–å¤–æ±‡æ¯æ—¥æ•°æ®",
        "digital_currency_daily": "è·å–æ•°å­—è´§å¸æ¯æ—¥æ•°æ®",
        "wti": "è·å–WTIåŸæ²¹ä»·æ ¼æ•°æ®",
        "brent": "è·å–BrentåŸæ²¹ä»·æ ¼æ•°æ®",
        "copper": "è·å–å…¨çƒé“œä»·æ•°æ®",
        "treasury_yield": "è·å–ç¾å›½å›½å€ºæ”¶ç›Šç‡æ•°æ®",
        "news_sentiment": "è·å–å¸‚åœºæ–°é—»å’Œæƒ…ç»ªæ•°æ®"
    }
    return descriptions.get(mode_name, "æœªçŸ¥åŠŸèƒ½")