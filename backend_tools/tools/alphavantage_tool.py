"""AlphaVantageÈáëËûçÊï∞ÊçÆËé∑ÂèñÂ∑•ÂÖ∑ - ÊúÄÁªà‰ºòÂåñÁâàÊú¨"""
import os
import logging
import json
import asyncio
import pandas as pd
import requests
from pathlib import Path
from typing import Dict, Any, List, Optional, Union, Literal
from pydantic import BaseModel, Field
from datetime import datetime
from enum import Enum
from tenacity import retry, stop_after_attempt, wait_exponential

# ÈÖçÁΩÆÊó•Âøó
logger = logging.getLogger(__name__)

# ==================== ÈÖçÁΩÆÂå∫ ====================
SESSION_WORKSPACE_ROOT = Path("/srv/sandbox_workspaces")
SESSION_TIMEOUT_HOURS = 24

# ==================== Êûö‰∏æÂÆö‰πâ ====================
class AlphaVantageMode(str, Enum):
    """AlphaVantageÂäüËÉΩÊ®°Âºè - 13‰∏™ÂÆåÊï¥ÂäüËÉΩ"""
    WEEKLY_ADJUSTED = "weekly_adjusted"
    GLOBAL_QUOTE = "global_quote"
    HISTORICAL_OPTIONS = "historical_options"
    EARNINGS_TRANSCRIPT = "earnings_transcript"
    INSIDER_TRANSACTIONS = "insider_transactions"
    ETF_PROFILE = "etf_profile"
    FOREX_DAILY = "forex_daily"
    DIGITAL_CURRENCY_DAILY = "digital_currency_daily"
    WTI = "wti"
    BRENT = "brent"
    COPPER = "copper"
    TREASURY_YIELD = "treasury_yield"
    NEWS_SENTIMENT = "news_sentiment"

# ==================== ÂèÇÊï∞Ê®°Âûã ====================
class WeeklyAdjustedParams(BaseModel):
    symbol: str = Field(description="ËÇ°Á•®‰ª£Á†ÅÔºåÂ¶ÇÔºöAAPL, MSFT")

class GlobalQuoteParams(BaseModel):
    symbol: str = Field(description="ËÇ°Á•®‰ª£Á†ÅÔºåÂ¶ÇÔºöAAPL, MSFT")

class HistoricalOptionsParams(BaseModel):
    symbol: str = Field(description="ËÇ°Á•®‰ª£Á†ÅÔºåÂ¶ÇÔºöAAPL")
    date: Optional[str] = Field(default=None, description="ÊúüÊùÉÂà∞ÊúüÊó•ÔºåÊ†ºÂºèÔºöYYYY-MM-DD")

class EarningsTranscriptParams(BaseModel):
    symbol: str = Field(description="ËÇ°Á•®‰ª£Á†ÅÔºåÂ¶ÇÔºöAAPL")
    quarter: str = Field(description="Â≠£Â∫¶ÔºåÊ†ºÂºèÔºöYYYY-Q1/Q2/Q3/Q4")

class InsiderTransactionsParams(BaseModel):
    symbol: str = Field(description="ËÇ°Á•®‰ª£Á†ÅÔºåÂ¶ÇÔºöAAPL")

class ETFProfileParams(BaseModel):
    symbol: str = Field(description="ETF‰ª£Á†ÅÔºåÂ¶ÇÔºöSPY, QQQ")

class ForexDailyParams(BaseModel):
    from_symbol: str = Field(default="USD", description="Ê∫êË¥ßÂ∏Å‰ª£Á†ÅÔºåÂ¶ÇÔºöUSD")
    to_symbol: str = Field(default="JPY", description="ÁõÆÊ†áË¥ßÂ∏Å‰ª£Á†ÅÔºåÂ¶ÇÔºöJPY")
    outputsize: Literal["compact", "full"] = Field(default="full", description="Êï∞ÊçÆÂ§ßÂ∞è")

class DigitalCurrencyDailyParams(BaseModel):
    symbol: str = Field(description="Êï∞Â≠óË¥ßÂ∏Å‰ª£Á†ÅÔºåÂ¶ÇÔºöBTC")
    market: str = Field(description="‰∫§ÊòìÂ∏ÇÂú∫ÔºåÂ¶ÇÔºöUSD, CNY")

class CommodityParams(BaseModel):
    interval: Literal["daily", "weekly", "monthly"] = Field(default="monthly", description="Êï∞ÊçÆÈó¥Èöî")

class TreasuryYieldParams(BaseModel):
    interval: Literal["daily", "weekly", "monthly"] = Field(default="monthly", description="Êï∞ÊçÆÈó¥Èöî")
    maturity: str = Field(default="10year", description="ÂõΩÂÄ∫ÊúüÈôêÔºåÂ¶ÇÔºö3month, 2year, 10year")

class NewsSentimentParams(BaseModel):
    tickers: Optional[str] = Field(default=None, description="ËÇ°Á•®‰ª£Á†ÅÔºåÂ§ö‰∏™Áî®ÈÄóÂè∑ÂàÜÈöî")
    topics: Optional[str] = Field(default=None, description="‰∏ªÈ¢òÔºåÂ§ö‰∏™Áî®ÈÄóÂè∑ÂàÜÈöî")
    time_from: Optional[str] = Field(default=None, description="ÂºÄÂßãÊó∂Èó¥ÔºåÊ†ºÂºèÔºöYYYYMMDDTHHMM")
    time_to: Optional[str] = Field(default=None, description="ÁªìÊùüÊó∂Èó¥ÔºåÊ†ºÂºèÔºöYYYYMMDDTHHMM")
    sort: Literal["LATEST", "EARLIEST", "RELEVANCE"] = Field(default="LATEST", description="ÊéíÂ∫èÊñπÂºè")
    limit: int = Field(default=50, ge=1, le=1000, description="ËøîÂõûÊï∞ÈáèÈôêÂà∂")

# Â∑•ÂÖ∑ËæìÂÖ•Ê®°Âûã
class AlphaVantageInput(BaseModel):
    """AlphaVantageÂ∑•ÂÖ∑ËæìÂÖ•Ê®°Âûã"""
    mode: AlphaVantageMode = Field(description="Ë¶ÅÊâßË°åÁöÑAlphaVantageÂäüËÉΩÊ®°Âºè")
    parameters: Dict[str, Any] = Field(description="ÂäüËÉΩÂèÇÊï∞")

# ==================== AlphaVantageÊï∞ÊçÆËé∑ÂèñÂô® ====================
class AlphaVantageFetcher:
    """AlphaVantageÊï∞ÊçÆËé∑ÂèñÂô® - ÂÆåÊï¥Áâà"""
    
    BASE_URL = "https://www.alphavantage.co/query"
    
    @staticmethod
    def get_api_key():
        """‰ªéÁéØÂ¢ÉÂèòÈáèËé∑ÂèñAPI Key"""
        key = os.getenv("ALPHAVANTAGE_API_KEY")
        if not key:
            logger.warning("‚ö†Ô∏è ALPHAVANTAGE_API_KEYÊú™ÊâæÂà∞Ôºå‰ΩøÁî®ÈªòËÆ§key")
            return "U5KM36DHDXR95Q7Q"  # ÈªòËÆ§key
        return key
    
    # ============ ËÇ°Á•®Êï∞ÊçÆÊñπÊ≥ï ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_weekly_adjusted(symbol: str, session_dir: Path = None) -> pd.DataFrame:
        """Ëé∑ÂèñÂë®Ë∞ÉÊï¥ÂêéÊï∞ÊçÆ"""
        try:
            params = {
                "function": "TIME_SERIES_WEEKLY_ADJUSTED",
                "symbol": symbol, 
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            time_series = data.get("Weekly Adjusted Time Series", {})
            if not time_series:
                raise ValueError("No weekly data found in response")

            df = pd.DataFrame.from_dict(time_series, orient="index")
            df.index = pd.to_datetime(df.index)
            df = df.sort_index()

            df = df.rename(columns={
                "1. open": "open",
                "2. high": "high",
                "3. low": "low",
                "4. close": "close",
                "5. adjusted close": "adjusted_close",
                "6. volume": "volume",
                "7. dividend amount": "dividend"
            })

            df = df.astype({
                "open": float,
                "high": float,
                "low": float,
                "close": float,
                "adjusted_close": float,
                "volume": int,
                "dividend": float
            })

            # üéØ ‰øùÂ≠òÂà∞‰ºöËØùÁõÆÂΩï
            if session_dir:
                file_path = session_dir / "stock" / f"{symbol}.parquet"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                df.to_parquet(file_path)
                logger.info(f"ËÇ°Á•®Êï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰ºöËØùÁõÆÂΩïÔºö{file_path}")
            else:
                # ÂêéÂ§áÔºö‰øùÂ≠òÂà∞‰∏¥Êó∂ÁõÆÂΩï
                temp_dir = Path("/tmp/alphavantage_data") / "us_stock"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"{symbol}.parquet"
                df.to_parquet(file_path)
                logger.info(f"ËÇ°Á•®Êï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰∏¥Êó∂ÁõÆÂΩïÔºö{file_path}")

            return df[["open", "high", "low", "close", "adjusted_close", "volume", "dividend"]]

        except Exception as e:
            logger.error(f"Ëé∑ÂèñAlphaVantageÊï∞ÊçÆÂ§±Ë¥•: {e}")
            raise
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_global_quote(symbol: str, session_dir: Path = None) -> Dict[str, Union[str, float, int]]:
        """Ëé∑ÂèñÂÆûÊó∂Ë°åÊÉÖÊï∞ÊçÆ"""
        try:
            params = {
                "function": "GLOBAL_QUOTE",
                "symbol": symbol,
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            quote = data.get("Global Quote", {})
            if not quote:
                raise ValueError("No quote data found in response")

            result = {
                'symbol': quote.get('01. symbol'),
                'open': float(quote.get('02. open', 0)) if quote.get('02. open', '') != '' else 0.0,
                'high': float(quote.get('03. high', 0)) if quote.get('03. high', '') != '' else 0.0,
                'low': float(quote.get('04. low', 0)) if quote.get('04. low', '') != '' else 0.0,
                'price': float(quote.get('05. price', 0)) if quote.get('05. price', '') != '' else 0.0,
                'volume': int(quote.get('06. volume', 0)) if quote.get('06. volume', '') != '' else 0,
                'latest_trading_day': quote.get('07. latest trading day'),
                'previous_close': float(quote.get('08. previous close', 0)) if quote.get('08. previous close', '') != '' else 0.0,
                'change': float(quote.get('09. change', 0)) if quote.get('09. change', '') != '' else 0.0,
                'change_percent': quote.get('10. change percent', '0%')
            }

            # üéØ ‰øùÂ≠òÂà∞‰ºöËØùÁõÆÂΩï
            if session_dir:
                file_path = session_dir / "stock" / f"{symbol}_quote.json"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                logger.info(f"ÂÆûÊó∂Ë°åÊÉÖÂ∑≤‰øùÂ≠òËá≥‰ºöËØùÁõÆÂΩïÔºö{file_path}")

            return result

        except Exception as e:
            logger.error(f"Ëé∑ÂèñÂÆûÊó∂Ë°åÊÉÖÂ§±Ë¥•: {e}")
            raise
    
    # ============ ÊúüÊùÉÊï∞ÊçÆÊñπÊ≥ï ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(2), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_historical_options(symbol: str, date: str = None, session_dir: Path = None) -> List[Dict]:
        """Ëé∑ÂèñÂéÜÂè≤ÊúüÊùÉÊï∞ÊçÆ"""
        try:
            params = {
                "function": "HISTORICAL_OPTIONS",
                "symbol": symbol,
                "apikey": AlphaVantageFetcher.get_api_key()
            }
            if date:
                params["date"] = date

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            # Ê£ÄÊü•APIËøîÂõûÁöÑÈîôËØØ‰ø°ÊÅØ
            if "Information" in data:
                error_msg = data["Information"]
                logger.warning(f"AlphaVantage APIÈôêÂà∂: {error_msg}")
                raise ValueError(f"ÈúÄË¶ÅAlphaVantage‰ªòË¥πAPIÂ•óÈ§êÊâçËÉΩËÆøÈóÆÊúüÊùÉÊï∞ÊçÆ: {error_msg}")
            
            if "Note" in data:
                logger.warning(f"APIÈ¢ëÁéáÈôêÂà∂ÊèêÁ§∫: {data['Note']}")
            
            if not data.get("data"):
                if "Error Message" in data:
                    raise ValueError(f"AlphaVantage APIÈîôËØØ: {data['Error Message']}")
                else:
                    logger.warning(f"Êú™ÊâæÂà∞{symbol}Âú®{date}ÁöÑÊúüÊùÉÊï∞ÊçÆ")
                    return []

            # ËΩ¨Êç¢Êï∞ÊçÆÁ±ªÂûã
            for contract in data["data"]:
                for field in ["strike", "last", "mark", "bid", "ask", 
                            "implied_volatility", "delta", "gamma", 
                            "theta", "vega", "rho"]:
                    if contract.get(field):
                        contract[field] = float(contract[field])
                for field in ["bid_size", "ask_size", "volume", "open_interest"]:
                    if contract.get(field):
                        contract[field] = int(contract[field])

            # üéØ ‰øùÂ≠òÂà∞‰ºöËØùÁõÆÂΩï
            if session_dir:
                file_path = session_dir / "options" / f"{symbol}_{date if date else 'latest'}.parquet"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                pd.DataFrame(data["data"]).to_parquet(file_path)
                logger.info(f"ÊúüÊùÉÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰ºöËØùÁõÆÂΩïÔºö{file_path}")
            else:
                # ÂêéÂ§á
                temp_dir = Path("/tmp/alphavantage_data") / "options"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"{symbol}_{date if date else 'latest'}.parquet"
                pd.DataFrame(data["data"]).to_parquet(file_path)
                logger.info(f"ÊúüÊùÉÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰∏¥Êó∂ÁõÆÂΩïÔºö{file_path}")

            return data["data"]

        except Exception as e:
            logger.error(f"Ëé∑ÂèñÊúüÊùÉÊï∞ÊçÆÂ§±Ë¥•: {e}")
            return []
    
    # ============ Ë¥¢Êä•Êï∞ÊçÆÊñπÊ≥ï ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_earnings_transcript(symbol: str, quarter: str, session_dir: Path = None) -> Dict:
        """Ëé∑ÂèñË¥¢Êä•ÁîµËØù‰ºöËÆÆËÆ∞ÂΩï"""
        try:
            params = {
                "function": "EARNINGS_CALL_TRANSCRIPT",
                "symbol": symbol,
                "quarter": quarter,
                "apikey": AlphaVantageFetcher.get_api_key()
            }
            
            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            # üéØ ‰øùÂ≠òÂà∞‰ºöËØùÁõÆÂΩï
            if session_dir:
                file_path = session_dir / "transcripts" / f"{symbol}_{quarter}.json"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False)
                logger.info(f"Ë¥¢Êä•‰ºöËÆÆËÆ∞ÂΩïÂ∑≤‰øùÂ≠òËá≥‰ºöËØùÁõÆÂΩïÔºö{file_path}")
            else:
                # ÂêéÂ§á
                temp_dir = Path("/tmp/alphavantage_data") / "transcripts"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"{symbol}_{quarter}.json"
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False)
                logger.info(f"Ë¥¢Êä•‰ºöËÆÆËÆ∞ÂΩïÂ∑≤‰øùÂ≠òËá≥‰∏¥Êó∂ÁõÆÂΩïÔºö{file_path}")

            return data
            
        except Exception as e:
            logger.error(f"Ëé∑ÂèñË¥¢Êä•‰ºöËÆÆËÆ∞ÂΩïÂ§±Ë¥•: {e}")
            raise
    
    # ============ ÂÜÖÈÉ®‰∫§ÊòìÊï∞ÊçÆÊñπÊ≥ï ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_insider_transactions(symbol: str, session_dir: Path = None) -> List[Dict]:
        """Ëé∑ÂèñÂÖ¨Âè∏ÂÜÖÈÉ®‰∫∫‰∫§ÊòìÊï∞ÊçÆ"""
        try:
            params = {
                "function": "INSIDER_TRANSACTIONS",
                "symbol": symbol,
                "apikey": AlphaVantageFetcher.get_api_key()
            }
            
            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            # ËΩ¨Êç¢Êï∞ÊçÆÁ±ªÂûã
            transactions = []
            for item in data.get("data", []):
                transactions.append({
                    "transaction_date": item.get("transaction_date"),
                    "ticker": item.get("ticker"),
                    "executive": item.get("executive"),
                    "executive_title": item.get("executive_title"),
                    "security_type": item.get("security_type"),
                    "acquisition_or_disposal": item.get("acquisition_or_disposal"),
                    "trade_type": "‰π∞ÂÖ•" if item.get("acquisition_or_disposal") == "A" else "ÂçñÂá∫",
                    "shares": float(item.get("shares", 0)) if item.get("shares") else 0,
                    "share_price": float(item.get("share_price", 0)) if item.get("share_price") else 0,
                    "total_value": float(item.get("shares", 0)) * float(item.get("share_price", 0)) if item.get("shares") and item.get("share_price") else 0
                })

            # üéØ ‰øùÂ≠òÂà∞‰ºöËØùÁõÆÂΩï
            if session_dir:
                file_path = session_dir / "insider" / f"{symbol}_insider.json"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(transactions, f, ensure_ascii=False)
                logger.info(f"ÂÜÖÈÉ®‰∫∫‰∫§ÊòìÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰ºöËØùÁõÆÂΩïÔºö{file_path}")
            else:
                # ÂêéÂ§á
                temp_dir = Path("/tmp/alphavantage_data") / "insider"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"{symbol}_insider.json"
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(transactions, f, ensure_ascii=False)
                logger.info(f"ÂÜÖÈÉ®‰∫∫‰∫§ÊòìÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰∏¥Êó∂ÁõÆÂΩïÔºö{file_path}")

            return transactions
            
        except Exception as e:
            logger.error(f"Ëé∑ÂèñÂÜÖÈÉ®‰∫∫‰∫§ÊòìÊï∞ÊçÆÂ§±Ë¥•: {e}")
            raise
    
    # ============ ETFÊï∞ÊçÆÊñπÊ≥ï ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_etf_profile(symbol: str, session_dir: Path = None) -> Dict:
        """Ëé∑ÂèñETFËØ¶ÁªÜ‰ø°ÊÅØÂíåÊåÅ‰ªìÊï∞ÊçÆ"""
        try:
            params = {
                "function": "ETF_PROFILE",
                "symbol": symbol,
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            # Ê†áÂáÜÂåñÊï∞ÊçÆÁªìÊûÑ
            profile = {
                "symbol": data.get("symbol", symbol),
                "name": data.get("name"),
                "description": data.get("description"),
                "exchange": data.get("exchange"),
                "net_assets": float(data.get("net_assets", 0)),
                "expense_ratio": float(data.get("expense_ratio", 0)),
                "portfolio_turnover": float(data.get("portfolio_turnover", 0)),
                "dividend_yield": float(data.get("dividend_yield", 0)),
                "inception_date": data.get("inception_date"),
                "leveraged": data.get("leveraged", "").upper() == "YES",
                "sectors": [],
                "holdings": []
            }

            # Â§ÑÁêÜË°å‰∏öÈÖçÁΩÆÊï∞ÊçÆ
            if isinstance(data.get("sectors"), list):
                for sector in data["sectors"]:
                    if isinstance(sector, dict):
                        profile["sectors"].append({
                            "sector": sector.get("sector"),
                            "weight": float(sector.get("weight", 0))
                        })

            # Â§ÑÁêÜÊåÅ‰ªìÊï∞ÊçÆ
            if isinstance(data.get("holdings"), list):
                for holding in data["holdings"]:
                    if isinstance(holding, dict):
                        profile["holdings"].append({
                            "symbol": holding.get("symbol"),
                            "name": holding.get("name"),
                            "weight": float(holding.get("weight", 0)),
                            "shares": int(holding.get("shares", 0)) 
                        })

            # üéØ ‰øùÂ≠òÂà∞‰ºöËØùÁõÆÂΩï
            if session_dir:
                file_path = session_dir / "etf" / f"{symbol}_profile.json"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(profile, f, ensure_ascii=False, indent=2)
                logger.info(f"ETFÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰ºöËØùÁõÆÂΩïÔºö{file_path}")
            else:
                # ÂêéÂ§á
                temp_dir = Path("/tmp/alphavantage_data") / "etf"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"{symbol}_profile.json"
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(profile, f, ensure_ascii=False, indent=2)
                logger.info(f"ETFÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰∏¥Êó∂ÁõÆÂΩïÔºö{file_path}")
            
            return profile
            
        except Exception as e:
            logger.error(f"Ëé∑ÂèñETFÊï∞ÊçÆÂ§±Ë¥•: {e}")
            raise
    
    # ============ Â§ñÊ±áÊï∞ÊçÆÊñπÊ≥ï ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_forex_daily(
        from_symbol: str = "USD",
        to_symbol: str = "JPY",
        outputsize: str = "full",
        session_dir: Path = None
    ) -> pd.DataFrame:
        """Ëé∑ÂèñÂ§ñÊ±áÊØèÊó•Êï∞ÊçÆ"""
        try:
            params = {
                "function": "FX_DAILY",
                "from_symbol": from_symbol,
                "to_symbol": to_symbol,
                "outputsize": outputsize,
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            time_series = data.get("Time Series FX (Daily)", {})
            if not time_series:
                raise ValueError(f"Êú™Ëé∑ÂèñÂà∞Â§ñÊ±áÊï∞ÊçÆÔºåÂìçÂ∫î: {data}")

            df = pd.DataFrame.from_dict(time_series, orient="index")
            df.index = pd.to_datetime(df.index)
            df = df.sort_index()

            df = df.rename(columns={
                "1. open": "open",
                "2. high": "high", 
                "3. low": "low",
                "4. close": "close"
            })

            df = df.astype({
                "open": float,
                "high": float,
                "low": float,
                "close": float
            })

            # üéØ ‰øùÂ≠òÂà∞‰ºöËØùÁõÆÂΩï
            if session_dir:
                file_path = session_dir / "forex" / f"{from_symbol}_{to_symbol}.parquet"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                df.to_parquet(file_path)
                logger.info(f"Â§ñÊ±áÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰ºöËØùÁõÆÂΩï: {file_path}")
            else:
                # ÂêéÂ§á
                temp_dir = Path("/tmp/alphavantage_data") / "forex"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"{from_symbol}_{to_symbol}_daily.parquet"
                df.to_parquet(file_path)
                logger.info(f"Â§ñÊ±áÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰∏¥Êó∂ÁõÆÂΩï: {file_path}")

            return df

        except Exception as e:
            logger.error(f"Ëé∑Âèñ{from_symbol}/{to_symbol}Â§ñÊ±áÊï∞ÊçÆÂ§±Ë¥•: {e}")
            raise
    
    # ============ Êï∞Â≠óË¥ßÂ∏ÅÊï∞ÊçÆÊñπÊ≥ï ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_digital_currency_daily(
        symbol: str,
        market: str,
        session_dir: Path = None
    ) -> Dict[str, pd.DataFrame]:
        """Ëé∑ÂèñÊï∞Â≠óË¥ßÂ∏ÅÊØèÊó•Êï∞ÊçÆ"""
        try:
            params = {
                "function": "DIGITAL_CURRENCY_DAILY",
                "symbol": symbol,
                "market": market,
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            time_series = data.get("Time Series (Digital Currency Daily)", {})
            if not time_series:
                raise ValueError(f"Êú™Ëé∑ÂèñÂà∞Êï∞Â≠óË¥ßÂ∏ÅÊï∞ÊçÆÔºåÂìçÂ∫î: {data}")

            # ËΩ¨Êç¢‰∏∫DataFrameÂπ∂Â§ÑÁêÜÊï∞ÊçÆ
            df = pd.DataFrame.from_dict(time_series, orient="index")
            df.index = pd.to_datetime(df.index)
            df = df.sort_index()

            # Â§ÑÁêÜÂ∏ÇÂú∫Ë¥ßÂ∏ÅÊï∞ÊçÆ
            if market == "USD":
                # USDÂ∏ÇÂú∫‰ΩøÁî®Âü∫Êú¨ÂàóÂêç
                market_df = df[[
                    "1. open",
                    "2. high",
                    "3. low",
                    "4. close",
                    "5. volume"
                ]].rename(columns={
                    "1. open": "open",
                    "2. high": "high",
                    "3. low": "low",
                    "4. close": "close",
                    "5. volume": "volume"
                })
                usd_df = market_df[["open", "high", "low", "close"]].copy()
            else:
                def get_column(df, prefix, currency):
                    """ËæÖÂä©ÂáΩÊï∞Ëé∑ÂèñÊåáÂÆöÂâçÁºÄÂíåÂ§ßÂ∞èÁöÑÂàó"""
                    for col in df.columns:
                        if f"{prefix}. " in col and f"({currency})" in col and not "(convert)" in col:
                            return col
                    raise ValueError(f"Êâæ‰∏çÂà∞{prefix} {currency}Âàó")

                # Ëé∑ÂèñÂ∏ÇÂú∫Ë¥ßÂ∏ÅËÆ°‰ª∑Êï∞ÊçÆÂàó
                market_open = get_column(df, "1a", market)
                market_high = get_column(df, "2a", market)
                market_low = get_column(df, "3a", market)
                market_close = get_column(df, "4a", market)
                volume_col = "5. volume"

                market_df = df[[
                    market_open,
                    market_high,
                    market_low,
                    market_close,
                    volume_col
                ]].rename(columns={
                    market_open: "open",
                    market_high: "high", 
                    market_low: "low",
                    market_close: "close",
                    volume_col: "volume"
                })

                # Ëé∑ÂèñÁæéÂÖÉËÆ°‰ª∑Êï∞ÊçÆÂàó
                usd_open = get_column(df, "1b", "USD")
                usd_high = get_column(df, "2b", "USD")
                usd_low = get_column(df, "3b", "USD")
                usd_close = get_column(df, "4b", "USD")

                usd_df = df[[
                    usd_open,
                    usd_high,
                    usd_low,
                    usd_close
                ]].rename(columns={
                    usd_open: "open",
                    usd_high: "high",
                    usd_low: "low",
                    usd_close: "close"
                })

            # ËΩ¨Êç¢Êï∞ÊçÆÁ±ªÂûã
            market_df = market_df.astype({
                "open": float, "high": float, "low": float, 
                "close": float, "volume": float
            })
            usd_df = usd_df.astype({
                "open": float, "high": float, "low": float, "close": float
            })

            # üéØ ‰øùÂ≠òÂà∞‰ºöËØùÁõÆÂΩï
            if session_dir:
                dir_path = session_dir / "crypto"
                dir_path.mkdir(parents=True, exist_ok=True)
                
                # ÁâπÊÆäÂ§ÑÁêÜUSDÂ∏ÇÂú∫Êï∞ÊçÆ
                if market == "USD":
                    file_path = dir_path / f"{symbol}_USD.parquet"
                    market_df.to_parquet(file_path)
                    logger.info(f"USDÂ∏ÇÂú∫Êï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰ºöËØùÁõÆÂΩï: {file_path}")
                else:
                    market_file = dir_path / f"{symbol}_{market}.parquet"
                    usd_file = dir_path / f"{symbol}_USD.parquet"
                    market_df.to_parquet(market_file)
                    usd_df.to_parquet(usd_file)
                    logger.info(f"Êï∞Â≠óË¥ßÂ∏Å{symbol}Êï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰ºöËØùÁõÆÂΩï: {dir_path}")
            else:
                # ÂêéÂ§á
                temp_dir = Path("/tmp/alphavantage_data") / "digital_currency"
                temp_dir.mkdir(parents=True, exist_ok=True)
                
                if market == "USD":
                    file_path = temp_dir / "USD_market_values.parquet"
                    market_df.to_parquet(file_path)
                    logger.info(f"USDÂ∏ÇÂú∫Êï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰∏¥Êó∂ÁõÆÂΩï: {file_path}")
                else:
                    market_df.to_parquet(temp_dir / f"{market}_market_values.parquet")
                    usd_df.to_parquet(temp_dir / "usd_market_values.parquet")
                    logger.info(f"Êï∞Â≠óË¥ßÂ∏Å{symbol}Êï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰∏¥Êó∂ÁõÆÂΩï: {temp_dir}")

            return {
                "market": market_df,
                "usd": usd_df
            }

        except Exception as e:
            logger.error(f"Ëé∑Âèñ{symbol}/{market}Êï∞Â≠óË¥ßÂ∏ÅÊï∞ÊçÆÂ§±Ë¥•: {e}")
            raise
    
    # ============ Â§ßÂÆóÂïÜÂìÅÊï∞ÊçÆÊñπÊ≥ï ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_wti(
        interval: str = "monthly",
        session_dir: Path = None
    ) -> pd.DataFrame:
        """Ëé∑ÂèñWTIÂéüÊ≤π‰ª∑Ê†ºÊï∞ÊçÆ"""
        try:
            params = {
                "function": "WTI",
                "interval": interval,
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            if not data.get("data"):
                raise ValueError("No WTI data found in response")

            # ËΩ¨Êç¢‰∏∫DataFrame
            df = pd.DataFrame(data["data"])
            df["date"] = pd.to_datetime(df["date"])
            df["price"] = pd.to_numeric(df["value"], errors='coerce')
            df = df.dropna(subset=['price'])
            df["price"] = df["price"].astype(float)
            df = df.drop(columns=["value"])
            df = df.set_index("date").sort_index()

            # üéØ ‰øùÂ≠òÂà∞‰ºöËØùÁõÆÂΩï
            if session_dir:
                file_path = session_dir / "commodities" / f"WTI_{interval}.parquet"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                df.to_parquet(file_path)
                logger.info(f"WTIÂéüÊ≤πÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰ºöËØùÁõÆÂΩï: {file_path}")
            else:
                # ÂêéÂ§á
                temp_dir = Path("/tmp/alphavantage_data") / "commodities"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"WTI_{interval}.parquet"
                df.to_parquet(file_path)
                logger.info(f"WTIÂéüÊ≤πÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰∏¥Êó∂ÁõÆÂΩï: {file_path}")

            return df

        except Exception as e:
            logger.error(f"Ëé∑ÂèñWTIÂéüÊ≤πÊï∞ÊçÆÂ§±Ë¥•: {e}")
            raise
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_brent(
        interval: str = "monthly",
        session_dir: Path = None
    ) -> pd.DataFrame:
        """Ëé∑ÂèñBrentÂéüÊ≤π‰ª∑Ê†ºÊï∞ÊçÆ"""
        try:
            params = {
                "function": "BRENT",
                "interval": interval,
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            if not data.get("data"):
                raise ValueError("No Brent data found in response")

            # ËΩ¨Êç¢‰∏∫DataFrameÂπ∂‰∏•Ê†ºÂ§ÑÁêÜÊï∞ÊçÆ
            df = pd.DataFrame(data["data"])
            df["date"] = pd.to_datetime(df["date"])
            df["price"] = pd.to_numeric(df["value"], errors='coerce')
            invalid_count = df["price"].isna().sum()
            if invalid_count > 0:
                logger.warning(f"ËøáÊª§Êéâ{invalid_count}Êù°Êó†ÊïàÂéüÊ≤πÊï∞ÊçÆ")
                df = df.dropna(subset=['price'])
            
            df["price"] = df["price"].astype(float)
            df = df.drop(columns=["value"])
            df = df.set_index("date").sort_index()
            
            if len(df) == 0:
                raise ValueError("Ê≤°ÊúâÊúâÊïàÁöÑÂéüÊ≤πÊï∞ÊçÆÂèØÁî®")

            # üéØ ‰øùÂ≠òÂà∞‰ºöËØùÁõÆÂΩï
            if session_dir:
                file_path = session_dir / "commodities" / f"BRENT_{interval}.parquet"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                df.to_parquet(file_path)
                logger.info(f"BrentÂéüÊ≤πÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰ºöËØùÁõÆÂΩï: {file_path}")
            else:
                # ÂêéÂ§á
                temp_dir = Path("/tmp/alphavantage_data") / "commodities"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"BRENT_{interval}.parquet"
                df.to_parquet(file_path)
                logger.info(f"BrentÂéüÊ≤πÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰∏¥Êó∂ÁõÆÂΩï: {file_path}")

            return df

        except Exception as e:
            logger.error(f"Ëé∑ÂèñBrentÂéüÊ≤πÊï∞ÊçÆÂ§±Ë¥•: {e}")
            raise
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_copper(
        interval: str = "monthly",
        session_dir: Path = None
    ) -> pd.DataFrame:
        """Ëé∑ÂèñÂÖ®ÁêÉÈìú‰ª∑Êï∞ÊçÆ"""
        try:
            params = {
                "function": "COPPER",
                "interval": interval,
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            if not data.get("data"):
                raise ValueError("No copper price data found in response")

            # ËΩ¨Êç¢‰∏∫DataFrameÂπ∂‰∏•Ê†ºÂ§ÑÁêÜÊï∞ÊçÆ
            df = pd.DataFrame(data["data"])
            df["date"] = pd.to_datetime(df["date"])
            df["price"] = pd.to_numeric(df["value"], errors='coerce')
            invalid_count = df["price"].isna().sum()
            if invalid_count > 0:
                logger.warning(f"ËøáÊª§Êéâ{invalid_count}Êù°Êó†ÊïàÈìú‰ª∑Êï∞ÊçÆ")
                df = df.dropna(subset=['price'])
            
            df["price"] = df["price"].astype(float)
            df = df.drop(columns=["value"])
            df = df.set_index("date").sort_index()
            
            if len(df) == 0:
                raise ValueError("Ê≤°ÊúâÊúâÊïàÁöÑÈìú‰ª∑Êï∞ÊçÆÂèØÁî®")

            # üéØ ‰øùÂ≠òÂà∞‰ºöËØùÁõÆÂΩï
            if session_dir:
                file_path = session_dir / "commodities" / f"COPPER_{interval}.parquet"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                df.to_parquet(file_path)
                logger.info(f"Èìú‰ª∑Êï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰ºöËØùÁõÆÂΩï: {file_path}")
            else:
                # ÂêéÂ§á
                temp_dir = Path("/tmp/alphavantage_data") / "commodities"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"COPPER_{interval}.parquet"
                df.to_parquet(file_path)
                logger.info(f"Èìú‰ª∑Êï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰∏¥Êó∂ÁõÆÂΩï: {file_path}")

            return df

        except Exception as e:
            logger.error(f"Ëé∑ÂèñÈìú‰ª∑Êï∞ÊçÆÂ§±Ë¥•: {e}")
            raise
    
    # ============ ÂõΩÂÄ∫Êî∂ÁõäÁéáÊï∞ÊçÆÊñπÊ≥ï ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10)) 
    def fetch_treasury_yield(
        interval: str = "monthly",
        maturity: str = "10year",
        session_dir: Path = None
    ) -> pd.DataFrame:
        """Ëé∑ÂèñÁæéÂõΩÂõΩÂÄ∫Êî∂ÁõäÁéáÊï∞ÊçÆ"""
        try:
            params = {
                "function": "TREASURY_YIELD",
                "interval": interval,
                "maturity": maturity,
                "apikey": AlphaVantageFetcher.get_api_key()
            }

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            if not data.get("data"):
                raise ValueError("Êú™Ëé∑ÂèñÂà∞ÂõΩÂÄ∫Êî∂ÁõäÁéáÊï∞ÊçÆ")
                
            # ËΩ¨Êç¢‰∏∫DataFrameÂπ∂Â§ÑÁêÜÊï∞ÊçÆ
            df = pd.DataFrame(data["data"])
            df["date"] = pd.to_datetime(df["date"])
            df["yield"] = pd.to_numeric(df["value"], errors="coerce")
            df = df.dropna(subset=["yield"])
            
            # üéØ ‰øùÂ≠òÂà∞‰ºöËØùÁõÆÂΩï
            if session_dir:
                file_path = session_dir / "treasury" / f"TREASURY_{maturity}_{interval}.parquet"
                file_path.parent.mkdir(parents=True, exist_ok=True)
                df.to_parquet(file_path)
                logger.info(f"ÂõΩÂÄ∫Êî∂ÁõäÁéáÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰ºöËØùÁõÆÂΩï: {file_path}")
            else:
                # ÂêéÂ§á
                temp_dir = Path("/tmp/alphavantage_data") / "treasury"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / f"TREASURY_{maturity}_{interval}.parquet"
                df.to_parquet(file_path)
                logger.info(f"ÂõΩÂÄ∫Êî∂ÁõäÁéáÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰∏¥Êó∂ÁõÆÂΩï: {file_path}")
            
            return df[["date", "yield"]]
            
        except Exception as e:
            logger.error(f"Ëé∑ÂèñÂõΩÂÄ∫Êî∂ÁõäÁéáÊï∞ÊçÆÂ§±Ë¥•: {e}")
            raise
    
    # ============ Êñ∞ÈóªÊÉÖÁª™Êï∞ÊçÆÊñπÊ≥ï ============
    
    @staticmethod
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def fetch_news_sentiment(
        tickers: str = None,
        topics: str = None,
        time_from: str = None,
        time_to: str = None,
        sort: str = "LATEST",
        limit: int = 50,
        session_dir: Path = None
    ) -> Dict:
        """Ëé∑ÂèñÂ∏ÇÂú∫Êñ∞ÈóªÂíåÊÉÖÁª™Êï∞ÊçÆ"""
        try:
            params = {
                "function": "NEWS_SENTIMENT",
                "apikey": AlphaVantageFetcher.get_api_key(),
                "sort": sort,
                "limit": limit
            }
            if tickers:
                params["tickers"] = tickers
            if topics:
                params["topics"] = topics
            if time_from:
                params["time_from"] = time_from
            if time_to:
                params["time_to"] = time_to

            response = requests.get(AlphaVantageFetcher.BASE_URL, params=params)
            response.raise_for_status()
            data = response.json()

            filename_parts = []
            if tickers:
                filename_parts.append(tickers.replace(',','_'))
            if topics:
                filename_parts.append(topics.replace(',','_'))
            if time_from:
                filename_parts.append(f"from_{time_from}")
            if time_to:
                filename_parts.append(f"to_{time_to}")
            if not filename_parts:
                filename_parts.append("latest")
            
            safe_filename = '_'.join(filename_parts).replace(':', '_').replace('/', '_').replace(' ', '_')
            filename = f"news_{safe_filename}.json"
            
            # üéØ ‰øùÂ≠òÂà∞‰ºöËØùÁõÆÂΩï
            if session_dir:
                file_path = session_dir / "news" / filename
                file_path.parent.mkdir(parents=True, exist_ok=True)
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False)
                logger.info(f"Êñ∞ÈóªÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰ºöËØùÁõÆÂΩïÔºö{file_path}")
            else:
                # ÂêéÂ§á
                temp_dir = Path("/tmp/alphavantage_data") / "news"
                temp_dir.mkdir(parents=True, exist_ok=True)
                file_path = temp_dir / filename
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False)
                logger.info(f"Êñ∞ÈóªÊï∞ÊçÆÂ∑≤‰øùÂ≠òËá≥‰∏¥Êó∂ÁõÆÂΩïÔºö{file_path}")

            return data

        except Exception as e:
            logger.error(f"Ëé∑ÂèñÊñ∞ÈóªÊï∞ÊçÆÂ§±Ë¥•: {e}")
            raise

# ==================== Â∑•ÂÖ∑Á±ª ====================
class AlphaVantageTool:
    """AlphaVantageÈáëËûçÊï∞ÊçÆËé∑ÂèñÂ∑•ÂÖ∑ - ÊúÄÁªà‰ºòÂåñÁâà"""
    
    name = "alphavantage"
    description = (
        "‰ªéAlphaVantageËé∑ÂèñÈáëËûçÊï∞ÊçÆÁöÑÂÆåÊï¥Â∑•ÂÖ∑„ÄÇÊîØÊåÅËÇ°Á•®„ÄÅÊúüÊùÉ„ÄÅË¥¢Êä•„ÄÅÂÜÖÈÉ®‰∫§Êòì„ÄÅETF„ÄÅÂ§ñÊ±á„ÄÅ"
        "Êï∞Â≠óË¥ßÂ∏Å„ÄÅÂ§ßÂÆóÂïÜÂìÅ„ÄÅÂõΩÂÄ∫Êî∂ÁõäÁéá„ÄÅÊñ∞ÈóªÊÉÖÁª™Á≠â13ÁßçÊï∞ÊçÆÁ±ªÂûã„ÄÇÊï∞ÊçÆ‰ºö‰øùÂ≠òÂà∞‰ºöËØùÂ∑•‰ΩúÂå∫„ÄÇ"
    )
    input_schema = AlphaVantageInput
    
    def __init__(self):
        # Á°Æ‰øùÂ∑•‰ΩúÂå∫Ê†πÁõÆÂΩïÂ≠òÂú®
        SESSION_WORKSPACE_ROOT.mkdir(exist_ok=True, parents=True)
        logger.info(f"AlphaVantageÂ∑•ÂÖ∑ÂàùÂßãÂåñÔºåÂ∑•‰ΩúÂå∫ÁõÆÂΩï: {SESSION_WORKSPACE_ROOT}")
        
        # È™åËØÅAPI Key
        self._validate_api_key()
        
        # Ê®°ÂºèÂà∞ÊñπÊ≥ïÊò†Â∞Ñ
        self._mode_to_method = {
            AlphaVantageMode.WEEKLY_ADJUSTED: {
                "method": AlphaVantageFetcher.fetch_weekly_adjusted,
                "params_model": WeeklyAdjustedParams,
                "timeout": 30
            },
            AlphaVantageMode.GLOBAL_QUOTE: {
                "method": AlphaVantageFetcher.fetch_global_quote,
                "params_model": GlobalQuoteParams,
                "timeout": 30
            },
            AlphaVantageMode.HISTORICAL_OPTIONS: {
                "method": AlphaVantageFetcher.fetch_historical_options,
                "params_model": HistoricalOptionsParams,
                "timeout": 45
            },
            AlphaVantageMode.EARNINGS_TRANSCRIPT: {
                "method": AlphaVantageFetcher.fetch_earnings_transcript,
                "params_model": EarningsTranscriptParams,
                "timeout": 45
            },
            AlphaVantageMode.INSIDER_TRANSACTIONS: {
                "method": AlphaVantageFetcher.fetch_insider_transactions,
                "params_model": InsiderTransactionsParams,
                "timeout": 30
            },
            AlphaVantageMode.ETF_PROFILE: {
                "method": AlphaVantageFetcher.fetch_etf_profile,
                "params_model": ETFProfileParams,
                "timeout": 30
            },
            AlphaVantageMode.FOREX_DAILY: {
                "method": AlphaVantageFetcher.fetch_forex_daily,
                "params_model": ForexDailyParams,
                "timeout": 30
            },
            AlphaVantageMode.DIGITAL_CURRENCY_DAILY: {
                "method": AlphaVantageFetcher.fetch_digital_currency_daily,
                "params_model": DigitalCurrencyDailyParams,
                "timeout": 30
            },
            AlphaVantageMode.WTI: {
                "method": AlphaVantageFetcher.fetch_wti,
                "params_model": CommodityParams,
                "timeout": 30
            },
            AlphaVantageMode.BRENT: {
                "method": AlphaVantageFetcher.fetch_brent,
                "params_model": CommodityParams,
                "timeout": 30
            },
            AlphaVantageMode.COPPER: {
                "method": AlphaVantageFetcher.fetch_copper,
                "params_model": CommodityParams,
                "timeout": 30
            },
            AlphaVantageMode.TREASURY_YIELD: {
                "method": AlphaVantageFetcher.fetch_treasury_yield,
                "params_model": TreasuryYieldParams,
                "timeout": 30
            },
            AlphaVantageMode.NEWS_SENTIMENT: {
                "method": AlphaVantageFetcher.fetch_news_sentiment,
                "params_model": NewsSentimentParams,
                "timeout": 45
            }
        }
    
    def _validate_api_key(self):
        """È™åËØÅAPI KeyÊòØÂê¶ÈÖçÁΩÆ"""
        try:
            api_key = AlphaVantageFetcher.get_api_key()
            if api_key and api_key != "U5KM36DHDXR95Q7Q":
                logger.info("‚úÖ AlphaVantage API Key Â∑≤Ê≠£Á°ÆÈÖçÁΩÆ")
            else:
                logger.warning("‚ö†Ô∏è AlphaVantage API Key Êú™ÈÖçÁΩÆÊàñ‰ΩøÁî®ÈªòËÆ§ÂÄºÔºåËØ∑Ê£ÄÊü•.envÊñá‰ª∂")
        except Exception as e:
            logger.error(f"È™åËØÅAPI KeyÊó∂Âá∫Èîô: {e}")
    
    def _ensure_session_workspace(self, session_id: str = None) -> Path:
        """Á°Æ‰øù‰ºöËØùÂ∑•‰ΩúÂå∫Â≠òÂú®"""
        if not session_id:
            # ‰∏¥Êó∂ÁõÆÂΩï
            temp_dir = SESSION_WORKSPACE_ROOT / "temp" / str(int(datetime.now().timestamp()))
            temp_dir.mkdir(parents=True, exist_ok=True)
            return temp_dir
        
        session_dir = SESSION_WORKSPACE_ROOT / session_id
        session_dir.mkdir(parents=True, exist_ok=True)
        
        # ÂàõÂª∫Â≠êÁõÆÂΩïÁªìÊûÑ
        subdirs = [
            "stock", "options", "transcripts", "insider", "etf", 
            "forex", "crypto", "commodities", "treasury", "news"
        ]
        
        for subdir in subdirs:
            (session_dir / subdir).mkdir(exist_ok=True)
        
        return session_dir
    
    async def _execute_with_timeout(self, func, timeout: int = 60):
        """Â∏¶Ë∂ÖÊó∂ÁöÑÂáΩÊï∞ÊâßË°å"""
        try:
            # Â∞ÜÂêåÊ≠•ÂáΩÊï∞ÂåÖË£Ö‰∏∫ÂºÇÊ≠•
            return await asyncio.wait_for(
                asyncio.get_event_loop().run_in_executor(None, func),
                timeout=timeout
            )
        except asyncio.TimeoutError:
            logger.error(f"‚è∞ Êìç‰ΩúË∂ÖÊó∂ ({timeout}Áßí)")
            raise
    
    async def execute(self, parameters: AlphaVantageInput, session_id: str = None) -> dict:
        """ÊâßË°åAlphaVantageÊï∞ÊçÆËé∑Âèñ - ‰∏ªÂÖ•Âè£"""
        try:
            mode = parameters.mode
            params = parameters.parameters
            
            logger.info(f"üöÄ ÊâßË°å AlphaVantage Ê®°Âºè: {mode.value}")
            
            # Ê£ÄÊü•Ê®°ÂºèÊòØÂê¶ÊîØÊåÅ
            if mode not in self._mode_to_method:
                return {
                    "success": False,
                    "error": f"‰∏çÊîØÊåÅÁöÑAlphaVantageÊ®°Âºè: {mode.value}",
                    "available_modes": [m.value for m in AlphaVantageMode]
                }
            
            # Á°Æ‰øù‰ºöËØùÂ∑•‰ΩúÂå∫
            session_dir = self._ensure_session_workspace(session_id)
            
            # Ëé∑ÂèñÊ®°ÂºèÈÖçÁΩÆ
            mode_config = self._mode_to_method[mode]
            method = mode_config["method"]
            params_model = mode_config["params_model"]
            timeout = mode_config["timeout"]
            
            # È™åËØÅÂèÇÊï∞
            try:
                validated_params = params_model(**params)
            except Exception as e:
                logger.error(f"‚ùå ÂèÇÊï∞È™åËØÅÂ§±Ë¥•: {e}")
                return {
                    "success": False,
                    "error": f"ÂèÇÊï∞È™åËØÅÂ§±Ë¥•: {str(e)}",
                    "mode": mode.value
                }
            
            # üéØ ÊâßË°åAPIË∞ÉÁî®
            try:
                result = await self._execute_with_timeout(
                    lambda: method(**validated_params.dict(), session_dir=session_dir),
                    timeout=timeout
                )
            except Exception as e:
                logger.error(f"‚ùå APIË∞ÉÁî®Â§±Ë¥•: {e}")
                return {
                    "success": False,
                    "error": f"APIË∞ÉÁî®Â§±Ë¥•: {str(e)}",
                    "mode": mode.value
                }
            
            # ÊûÑÂª∫ÂÖÉÊï∞ÊçÆ
            metadata = {
                "mode": mode.value,
                "parameters": params,
                "session_id": session_id,
                "timestamp": datetime.now().isoformat(),
                "session_dir": str(session_dir),
                "saved_files": self._get_saved_file_paths(session_dir, mode, params)
            }
            
            # Â§ÑÁêÜÁªìÊûú
            processed_result = self._process_result(result, mode)
            
            # ÊûÑÂª∫ÂìçÂ∫î
            response = {
                "success": True,
                "data": processed_result,
                "metadata": metadata
            }
            
            # Ê∑ªÂä†Á§∫‰æã‰ª£Á†Å
            if session_id:
                example_code = self._generate_example_code(mode, params, session_dir)
                response["metadata"]["example_code"] = example_code
                response["metadata"]["instructions"] = (
                    f"Êï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞‰ºöËØùÁõÆÂΩï {session_dir}Ôºå"
                    f"‰ª£Á†ÅËß£ÈáäÂô®ÂèØ‰ª•ÈÄöËøá '/srv/sandbox_workspaces/{session_id}/' ËÆøÈóÆËøô‰∫õÊñá‰ª∂„ÄÇ"
                )
            
            logger.info(f"‚úÖ AlphaVantageÂ∑•ÂÖ∑ÊâßË°åÊàêÂäü: {mode.value}")
            return response
            
        except Exception as e:
            logger.error(f"‚ùå AlphaVantageÂ∑•ÂÖ∑ÊâßË°åÂ§±Ë¥•: {str(e)}", exc_info=True)
            return {
                "success": False,
                "error": f"Â∑•ÂÖ∑ÊâßË°åÂ§±Ë¥•: {str(e)}",
                "mode": parameters.mode.value if hasattr(parameters, 'mode') else "unknown"
            }
    
    def _get_saved_file_paths(self, session_dir: Path, mode: AlphaVantageMode, params: dict) -> List[str]:
        """Ëé∑ÂèñÂ∑≤‰øùÂ≠òÁöÑÊñá‰ª∂Ë∑ØÂæÑ"""
        try:
            if mode == AlphaVantageMode.WEEKLY_ADJUSTED:
                symbol = params.get("symbol")
                if symbol:
                    file_path = session_dir / "stock" / f"{symbol}.parquet"
                    return [str(file_path)] if file_path.exists() else []
            
            elif mode == AlphaVantageMode.GLOBAL_QUOTE:
                symbol = params.get("symbol")
                if symbol:
                    file_path = session_dir / "stock" / f"{symbol}_quote.json"
                    return [str(file_path)] if file_path.exists() else []
            
            elif mode == AlphaVantageMode.FOREX_DAILY:
                from_sym = params.get("from_symbol", "USD")
                to_sym = params.get("to_symbol", "JPY")
                file_path = session_dir / "forex" / f"{from_sym}_{to_sym}.parquet"
                return [str(file_path)] if file_path.exists() else []
            
            elif mode == AlphaVantageMode.NEWS_SENTIMENT:
                tickers = params.get("tickers", "general")
                safe_tickers = tickers.replace(',', '_').replace(' ', '_') if tickers else "general"
                file_path = session_dir / "news" / f"news_{safe_tickers}.json"
                return [str(file_path)] if file_path.exists() else []
            
            # ÂÖ∂‰ªñÊ®°ÂºèÂèØ‰ª•Á±ª‰ººÊ∑ªÂä†...
            
            return []
        except Exception as e:
            logger.warning(f"Ëé∑Âèñ‰øùÂ≠òÊñá‰ª∂Ë∑ØÂæÑÂ§±Ë¥•: {e}")
            return []
    
    def _process_result(self, result, mode: AlphaVantageMode):
        """Â§ÑÁêÜËøîÂõûÁªìÊûúÔºåÁ°Æ‰øùÂèØÂ∫èÂàóÂåñ"""
        if result is None:
            return {"message": "Êú™Ëé∑ÂèñÂà∞Êï∞ÊçÆ"}
        
        # ÁâπÊÆäÂ§ÑÁêÜÊï∞Â≠óË¥ßÂ∏ÅÊï∞ÊçÆ
        if mode == AlphaVantageMode.DIGITAL_CURRENCY_DAILY:
            if isinstance(result, dict) and "market" in result and "usd" in result:
                processed_result = {}
                
                # Â§ÑÁêÜ market DataFrame
                if hasattr(result["market"], 'to_dict'):
                    market_df = result["market"]
                    processed_result["market"] = self._process_dataframe(market_df)
                
                # Â§ÑÁêÜ usd DataFrame
                if hasattr(result["usd"], 'to_dict'):
                    usd_df = result["usd"]
                    processed_result["usd"] = self._process_dataframe(usd_df)
                
                return processed_result
        
        # Â§ÑÁêÜ DataFrame
        if hasattr(result, 'to_dict'):
            return self._process_dataframe(result)
        
        # Â§ÑÁêÜÂ≠óÂÖ∏ÊàñÂàóË°®
        if isinstance(result, (dict, list)):
            if isinstance(result, list) and len(result) > 100:
                return {
                    "total_records": len(result),
                    "sample_data": result[:10],
                    "message": f"Êï∞ÊçÆËøáÂ§öÔºåÊòæÁ§∫Ââç10Êù°ÔºåÂÖ±{len(result)}Êù°"
                }
            return result
        
        return {"result": str(result)}
    
    def _process_dataframe(self, df):
        """Â§ÑÁêÜDataFrameËΩ¨Êç¢‰∏∫ÂèØÂ∫èÂàóÂåñÊ†ºÂºè"""
        try:
            if hasattr(df, 'index'):
                df_processed = df.reset_index()
                if 'index' in df_processed.columns:
                    df_processed = df_processed.rename(columns={'index': 'date'})
                
                if len(df_processed) > 100:
                    return {
                        "total_records": len(df_processed),
                        "date_range": {
                            "start": str(df_processed['date'].min()) if 'date' in df_processed.columns else None,
                            "end": str(df_processed['date'].max()) if 'date' in df_processed.columns else None
                        },
                        "sample_data": df_processed.head(10).to_dict(orient='records'),
                        "message": f"Êï∞ÊçÆËøáÂ§öÔºåÊòæÁ§∫Ââç10Êù°ÔºåÂÖ±{len(df_processed)}Êù°"
                    }
                else:
                    return df_processed.to_dict(orient='records')
            else:
                return df.to_dict(orient='records')
        except Exception as e:
            logger.warning(f"DataFrameËΩ¨Êç¢Â§±Ë¥•: {e}")
            return {"raw_result": str(df)}
    
    def _generate_example_code(self, mode: AlphaVantageMode, params: dict, session_dir: Path) -> str:
        """ÁîüÊàêPython‰ª£Á†ÅÁ§∫‰æã"""
        if mode == AlphaVantageMode.WEEKLY_ADJUSTED:
            symbol = params.get("symbol", "UNKNOWN")
            return f'''# ËØªÂèñ {symbol} ËÇ°Á•®Êï∞ÊçÆ
import pandas as pd
from pathlib import Path

# ‰ºöËØùÊï∞ÊçÆË∑ØÂæÑ
data_path = Path('/srv/sandbox_workspaces/{session_dir.name}/stock/{symbol}.parquet')
if data_path.exists():
    df = pd.read_parquet(data_path)
    print(f"{{'{symbol}'}} ËÇ°Á•®Êï∞ÊçÆ:")
    print(f"Êï∞ÊçÆÂΩ¢Áä∂: {{df.shape}}")
    print(f"Êó•ÊúüËåÉÂõ¥: {{df.index.min()}} Âà∞ {{df.index.max()}}")
    print("\\nÂâç5Ë°åÊï∞ÊçÆ:")
    print(df.head())
    
    # ÂèØËßÜÂåñ
    import matplotlib.pyplot as plt
    plt.figure(figsize=(12, 6))
    plt.plot(df.index, df['close'], label='Êî∂Áõò‰ª∑', linewidth=2)
    plt.title(f'{symbol} ËÇ°‰ª∑Ëµ∞Âäø')
    plt.xlabel('Êó•Êúü')
    plt.ylabel('‰ª∑Ê†º (USD)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()'''
        
        elif mode == AlphaVantageMode.FOREX_DAILY:
            from_sym = params.get("from_symbol", "USD")
            to_sym = params.get("to_symbol", "JPY")
            return f'''# ËØªÂèñ {from_sym}/{to_sym} Â§ñÊ±áÊï∞ÊçÆ
import pandas as pd
from pathlib import Path

# ‰ºöËØùÊï∞ÊçÆË∑ØÂæÑ
data_path = Path('/srv/sandbox_workspaces/{session_dir.name}/forex/{from_sym}_{to_sym}.parquet')
if data_path.exists():
    df = pd.read_parquet(data_path)
    print(f"{{'{from_sym}/{to_sym}'}} Â§ñÊ±áÊï∞ÊçÆ:")
    print(f"Êï∞ÊçÆÂΩ¢Áä∂: {{df.shape}}")
    print("\\nÊúÄËøë10Â§©Êï∞ÊçÆ:")
    print(df.tail(10))
    
    # ËÆ°ÁÆóÊî∂ÁõäÁéá
    df['returns'] = df['close'].pct_change()
    print("\\nÊî∂ÁõäÁéáÁªüËÆ°:")
    print(df['returns'].describe())'''
        
        else:
            return f'''# ËÆøÈóÆ‰ºöËØùÁõÆÂΩï‰∏≠ÁöÑÊâÄÊúâÊï∞ÊçÆ
import pandas as pd
import json
from pathlib import Path

# ‰ºöËØùÁõÆÂΩïË∑ØÂæÑ
session_path = Path('/srv/sandbox_workspaces/{session_dir.name}')
print("‰ºöËØùÁõÆÂΩï:", session_path)

# ÂàóÂá∫ÊâÄÊúâÂèØÁî®Êñá‰ª∂
print("\\nÂèØÁî®Êñá‰ª∂:")
for file_path in session_path.rglob("*"):
    if file_path.is_file():
        rel_path = file_path.relative_to(session_path)
        size_kb = file_path.stat().st_size / 1024
        print(f"  - {{rel_path}} ({{size_kb:.1f}} KB)")'''

# ==================== ËæÖÂä©ÂáΩÊï∞ ====================
def get_available_modes() -> List[str]:
    """Ëé∑ÂèñÊâÄÊúâÂèØÁî®ÁöÑAlphaVantageÊ®°Âºè"""
    return [mode.value for mode in AlphaVantageMode]

def get_mode_description(mode_name: str) -> str:
    """Ëé∑ÂèñÊ®°ÂºèÊèèËø∞"""
    descriptions = {
        "weekly_adjusted": "Ëé∑ÂèñËÇ°Á•®Âë®Ë∞ÉÊï¥Êï∞ÊçÆÔºàÂºÄÁõò‰ª∑„ÄÅÊúÄÈ´ò‰ª∑„ÄÅÊúÄ‰Ωé‰ª∑„ÄÅÊî∂Áõò‰ª∑„ÄÅË∞ÉÊï¥ÂêéÊî∂Áõò‰ª∑„ÄÅÊàê‰∫§Èáè„ÄÅËÇ°ÊÅØÔºâ",
        "global_quote": "Ëé∑ÂèñÂÆûÊó∂Ë°åÊÉÖÊï∞ÊçÆÔºàÂΩìÂâç‰ª∑Ê†º„ÄÅÊ∂®Ë∑åÂπÖ„ÄÅÊàê‰∫§ÈáèÁ≠âÔºâ",
        "historical_options": "Ëé∑ÂèñÂéÜÂè≤ÊúüÊùÉÊï∞ÊçÆÔºàÈúÄË¶Å‰ªòË¥πAPIÂ•óÈ§êÔºâ",
        "earnings_transcript": "Ëé∑ÂèñË¥¢Êä•ÁîµËØù‰ºöËÆÆËÆ∞ÂΩï",
        "insider_transactions": "Ëé∑ÂèñÂÖ¨Âè∏ÂÜÖÈÉ®‰∫∫‰∫§ÊòìÊï∞ÊçÆ",
        "etf_profile": "Ëé∑ÂèñETFËØ¶ÁªÜ‰ø°ÊÅØÂíåÊåÅ‰ªìÊï∞ÊçÆ",
        "forex_daily": "Ëé∑ÂèñÂ§ñÊ±áÊØèÊó•Êï∞ÊçÆ",
        "digital_currency_daily": "Ëé∑ÂèñÊï∞Â≠óË¥ßÂ∏ÅÊØèÊó•Êï∞ÊçÆ",
        "wti": "Ëé∑ÂèñWTIÂéüÊ≤π‰ª∑Ê†ºÊï∞ÊçÆ",
        "brent": "Ëé∑ÂèñBrentÂéüÊ≤π‰ª∑Ê†ºÊï∞ÊçÆ",
        "copper": "Ëé∑ÂèñÂÖ®ÁêÉÈìú‰ª∑Êï∞ÊçÆ",
        "treasury_yield": "Ëé∑ÂèñÁæéÂõΩÂõΩÂÄ∫Êî∂ÁõäÁéáÊï∞ÊçÆ",
        "news_sentiment": "Ëé∑ÂèñÂ∏ÇÂú∫Êñ∞ÈóªÂíåÊÉÖÁª™Êï∞ÊçÆ"
    }
    return descriptions.get(mode_name, "Êú™Áü•ÂäüËÉΩ")